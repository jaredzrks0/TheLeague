{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import statistics\n",
    "#from basketball_reference_web_scraper import client\n",
    "#from basketball_reference_web_scraper.data import OutputType\n",
    "#import hockey_scraper\n",
    "import datetime\n",
    "import requests\n",
    "from sportsipy.nfl.boxscore import Boxscore, BoxscorePlayer\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import time\n",
    "import statistics\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import re, os\n",
    "import time\n",
    "import random\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import clear_output\n",
    "from baseball_scraper import batting_stats_range, pitching_stats_range, baseball_reference\n",
    "from sportsipy.mlb.boxscore import Boxscores\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from openpyxl.styles import Border, Side\n",
    "from openpyxl.styles import Alignment, PatternFill, Font\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "waiver_participants = [\"Arron\", \"Adam\", \"Ben\", \"Brian\", \"Emmett\", \"Jordan\", \"Josh\", \"Phil\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Links for Later\n",
    "#current_rosters_path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Starter Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = [\"Noah\", \"Julia\", \"Jared\", \"Alex\", \"Josh\", \"Jordan\", \"Dalton\", \"Jesse\", \"Raphy\"]\n",
    "# day = 31\n",
    "# month = 12\n",
    "\n",
    "# annual_stats = {\"NFL\":{\"players\":pd.DataFrame(), \"teams\":pd.DataFrame()}, \"NHL\":{\"players\":pd.DataFrame(), \"teams\":pd.DataFrame()},\n",
    "#                                          \"NBA\":{\"players\":pd.DataFrame(), \"teams\":pd.DataFrame()}, \"MLB\":{\"players\":pd.DataFrame(), \"teams\":pd.DataFrame()}}\n",
    "\n",
    "# league_stats_by_participant = {}\n",
    "# for name in names:\n",
    "#     league_stats_by_participant[name] = {\"NFL\":{\"players\":pd.DataFrame(), \"teams\":pd.DataFrame()}, \"NHL\":{\"players\":pd.DataFrame(), \"teams\":pd.DataFrame()},\n",
    "#                                          \"NBA\":{\"players\":pd.DataFrame(), \"teams\":pd.DataFrame()}, \"MLB\":{\"players\":pd.DataFrame(), \"teams\":pd.DataFrame()}}\n",
    "\n",
    "# pkl.dump(league_stats_by_participant.copy(), open(\"/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/League Stats By Participant/League Stats By Participant {}-{}.pkl\".format(str(month).zfill(2), str(day).zfill(2)), \"wb\"))\n",
    "# pkl.dump(annual_stats.copy(), open(\"/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Annual League Stats/Annual Stats {}-{}.pkl\".format(str(month).zfill(2), str(day).zfill(2)), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# General Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import important files\n",
    "nhl_name_conversions = pd.read_excel(\"/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Team Name Conversions.xlsx\",\n",
    "                                     sheet_name=\"NHL Name Conversions\", header = 2).iloc[:, 3:]\n",
    "\n",
    "nfl_name_conversions = pd.read_excel(\"/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Team Name Conversions.xlsx\",\n",
    "                                     sheet_name=\"NFL Name Conversions\", header = 2).iloc[:, 1:]\n",
    "\n",
    "mlb_name_conversions = pd.read_excel(\"/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Team Name Conversions.xlsx\",\n",
    "                                     sheet_name=\"MLB Name Conversions\", header = 2).iloc[:, 3:]\n",
    "\n",
    "nba_name_conversions = pd.read_excel(\"/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Team Name Conversions.xlsx\",\n",
    "                                     sheet_name=\"NBA Name Conversions\", header = 2).iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_positions = [\"Pitcher\", \"Catcher\", \"First Base\", \"Second Base\", \"Third Base\", \"Short Stop\", \"Left Field\", \"Center Field\", \"Right Field\"]\n",
    "nfl_positons = [\"Quarterback\", \"Running Back\", \"Wide Reciever\", \"Tight End\", \"Punter\", \"Kicker\", \"Returner\", \"Defense\"]\n",
    "nhl_positions = [\"Goalie\", \"Right Wing\", \"Centerman\", \"Left Wing\", \"Defenseman\"]\n",
    "nba_positions = [\"Point Guard\", \"Shooting Guard\", \"Small Forward\", \"Power Forward\", \"Center\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_columns = {1:\"A\", 2:\"B\", 3:\"C\", 4:\"D\", 5:\"E\", 6:\"F\", 7:\"G\", 8:\"H\", 9:\"I\", 10:\"J\", 11:\"K\", 12:\"L\", 13:\"M\", 14:\"N\", 15:\"O\", 16:\"P\", 17:\"Q\", 18:\"R\", 19:\"S\", 20:\"T\", 21:\"U\",\n",
    "                22:\"V\", 23:\"W\", 24:\"X\", 25:\"Y\", 26:\"Z\", 27:\"AA\", 28:\"AB\", 29:\"AC\", 30:\"AD\", 31:\"AE\", 32:\"AF\", 33:\"AG\", 34:\"AH\", 35:\"AI\", 36:\"AJ\", 37:\"AK\", 38:\"AL\", 39:\"AM\", 40:\"AN\", \n",
    "                41:\"AO\", 42:\"AP\", 43:\"AQ\", 44:\"AR\", 45:\"AS\", 46:\"AT\", 47:\"AU\", 48:\"AV\", 49:\"AW\", 50:\"AX\", 51:\"AY\", 52:\"AZ\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTables(url):\n",
    "    \"\"\"Pulls all the relevant table ids from sports reference\"\"\"\n",
    "    res = requests.get(url)\n",
    "    ## The next two lines get around the issue with comments breaking the parsing.\n",
    "    comm = re.compile(\"<!--|-->\")\n",
    "    soup = BeautifulSoup(comm.sub(\"\", res.text), 'lxml')\n",
    "    divs = soup.findAll('div', id = \"content\")\n",
    "    divs = divs[0].findAll(\"div\", id=re.compile(\"^all\"))\n",
    "    ids = []\n",
    "    for div in divs:\n",
    "        searchme = str(div.findAll(\"table\"))\n",
    "        x = searchme[searchme.find(\"id=\") + 3: searchme.find(\">\")]\n",
    "        x = x.replace(\"\\\"\", \"\")\n",
    "        if len(x) > 0:\n",
    "            ids.append(x)\n",
    "    return(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nhl_season(day, month, year):\n",
    "    \"\"\"The url for scraping NHL games channges depending on which season were in, but the season doesn't directly correlate to the year. This returns the correct year to use in the URL based on the date\n",
    "       If we play another season in 2023, make sure to update with further dates\"\"\"\n",
    "    \n",
    "    \n",
    "    date = str(year) + \"-\" + str(month).zfill(2) + \"-\" + str(day).zfill(2)\n",
    "    if date > \"2022-06-30\":\n",
    "        return \"2023\"\n",
    "    elif date > \"2021-07-07\":\n",
    "        return \"2022\"\n",
    "    else:\n",
    "        return \"2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_dates = pd.read_excel(\"/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/2023 Important Dates.xlsx\", header = 1)\n",
    "#start_dates = important_dates[\"Start Date\"].dropna().apply(lambda x: x.strftime(\"%Y/%m/%d\"))\n",
    "#end_dates = important_dates[\"End Date\"].dropna().apply(lambda x: x.strftime(\"%Y/%m/%d\"))\n",
    "playing_dates = important_dates[\"Playing Days\"].apply(lambda x: x.strftime(\"%Y/%m/%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get what period we are currently in for later use\n",
    "start_dates = pd.date_range(\"1/3/2022\", \"12/20/2022\", freq=\"14D\")\n",
    "start_dates = [x.strftime(\"%Y/%m/%d\") for x in start_dates]\n",
    "\n",
    "end_dates = pd.date_range(\"1/15/2023\", \"12/31/2023\", freq=\"14D\")\n",
    "end_dates = [x.strftime(\"%Y/%m/%d\") for x in end_dates]\n",
    "\n",
    "dates = {num:{\"start\":[], \"end\":[]} for num in range(1,27)}\n",
    "for num in dates:\n",
    "    dates[num][\"start\"] = start_dates[num-1]\n",
    "    dates[num][\"end\"] = end_dates[num-1]\n",
    "\n",
    "def get_current_period(start_dates, year, month, day):\n",
    "     \n",
    "    if dt.datetime(year, month, day).strftime(\"%Y/%m/%d\") in start_dates:\n",
    "        trigger = 1\n",
    "    else:\n",
    "        trigger = 0    \n",
    "    \n",
    "    start_date = start_dates.copy()\n",
    "    start_date.append(dt.datetime(year, month, day).strftime(\"%Y/%m/%d\"))\n",
    "    full_date_series = pd.Series(start_date).sort_values(ascending = True).reset_index(drop = True)\n",
    "    current_period = full_date_series[full_date_series == dt.datetime(year, month, day).strftime(\"%Y/%m/%d\")].index[0]\n",
    "    \n",
    "    return current_period + trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_dict = {\"NFL\":{\"All Purpose Yards\":0.06, \"All Purpose TDs\":4.6, \"Attempts\":0.4, \"Return Yards\":0.15, \"Kicking Yards\":0.12, \"Sacks/Turnovers\":2.75},\n",
    "                \"NHL\":{\"Hockey Points\":1, \"Hockey Hits\":0.6, \"Hockey Blocks\":0.65, \"Penalty Minutes\":-1.25, \"Shots\":0.22, \"Goals Against\":-1.1, \"Saves\":0.25},\n",
    "                \"NBA\":{\"Three Pointers\":0.28, \"Free Throws Made\":0.14, \"Rebounds\":0.06, \"Assists\":0.11, \"Steals\":0.43, \"Blocks\":0.56, \"Turnovers\":-0.2, \"Points\":0.03},\n",
    "                \"MLB\":{\"Runs\":0.56, \"Home Runs\":1.2, \"RBIs\":0.57, \"Stolen Bases\":2.5, \"Walks\":0.76, \"Strikeouts\":-0.25, \"Total Bases\":0.18, \"Innings\":1.1, \"Earned Runs\":-3.5, \"Pitching Strikeouts\":0.9, \"Saves\":0.75}}\n",
    "\n",
    "positional_scoring_dict = {\"NFL\":{\"Quarterback\":[\"All Purpose Yards\", \"All Purpose TDs\", \"Attempts\"],\n",
    "                                  \"Running Back\":[\"All Purpose Yards\", \"All Purpose TDs\", \"Attempts\"],\n",
    "                                  \"Wide Reciever\":[\"All Purpose Yards\", \"All Purpose TDs\", \"Attempts\"],\n",
    "                                  \"Tight End\":[\"All Purpose Yards\", \"All Purpose TDs\", \"Attempts\"],\n",
    "                                  \"Kicker\":[\"Kicking Yards\"],\n",
    "                                  \"Punter\":[\"Kicking Yards\"],\n",
    "                                  \"Returner\":[\"Return Yards\"],\n",
    "                                  \"Defense\":[\"Sacks/Turnovers\"]\n",
    "                                  },\n",
    "                            \n",
    "                            \"MLB\":{\"Catcher\":[\"Runs\", \"Home Runs\", \"RBIs\", \"Stolen Bases\", \"Walks\", \"Strikeouts\", \"Total Bases\"],\n",
    "                                   \"First Base\":[\"Runs\", \"Home Runs\", \"RBIs\", \"Stolen Bases\", \"Walks\", \"Strikeouts\", \"Total Bases\"],\n",
    "                                   \"Second Base\":[\"Runs\", \"Home Runs\", \"RBIs\", \"Stolen Bases\", \"Walks\", \"Strikeouts\", \"Total Bases\"],\n",
    "                                   \"Third Base\":[\"Runs\", \"Home Runs\", \"RBIs\", \"Stolen Bases\", \"Walks\", \"Strikeouts\", \"Total Bases\"],\n",
    "                                   \"Short Stop\":[\"Runs\", \"Home Runs\", \"RBIs\", \"Stolen Bases\", \"Walks\", \"Strikeouts\", \"Total Bases\"],\n",
    "                                   \"Outfield\":[\"Runs\", \"Home Runs\", \"RBIs\", \"Stolen Bases\", \"Walks\", \"Strikeouts\", \"Total Bases\"],\n",
    "                                   \"Pitcher\":[\"Innings\", \"Earned Runs\", \"Pitching Strikeouts\", \"Saves\"]\n",
    "                                  },\n",
    "                            \n",
    "                            \"NBA\":{\"Point Guard\":[\"Three Pointers\", \"Free Throws Made\", \"Rebounds\", \"Assists\", \"Steals\", \"Blocks\", \"Turnovers\", \"Points\"],\n",
    "                                   \"Shooting Guard\":[\"Three Pointers\", \"Free Throws Made\", \"Rebounds\", \"Assists\", \"Steals\", \"Blocks\", \"Turnovers\", \"Points\"],\n",
    "                                   \"Small Forward\":[\"Three Pointers\", \"Free Throws Made\", \"Rebounds\", \"Assists\", \"Steals\", \"Blocks\", \"Turnovers\", \"Points\"],\n",
    "                                   \"Power Forward\":[\"Three Pointers\", \"Free Throws Made\", \"Rebounds\", \"Assists\", \"Steals\", \"Blocks\", \"Turnovers\", \"Points\"],\n",
    "                                   \"Center\":[\"Three Pointers\", \"Free Throws Made\", \"Rebounds\", \"Assists\", \"Steals\", \"Blocks\", \"Turnovers\", \"Points\"]\n",
    "                                  },\n",
    "                            \n",
    "                            \"NHL\":{\"Centerman\":[\"Hockey Points\", \"Hockey Hits\", \"Hockey Blocks\", \"Penalty Minutes\", \"Shots\"],\n",
    "                                   \"Right Wing\":[\"Hockey Points\", \"Hockey Hits\", \"Hockey Blocks\", \"Penalty Minutes\", \"Shots\"],\n",
    "                                   \"Centerman\":[\"Hockey Points\", \"Hockey Hits\", \"Hockey Blocks\", \"Penalty Minutes\", \"Shots\"],\n",
    "                                   \"Left Wing\":[\"Hockey Points\", \"Hockey Hits\", \"Hockey Blocks\", \"Penalty Minutes\", \"Shots\"],\n",
    "                                   \"Defenseman\":[\"Hockey Points\", \"Hockey Hits\", \"Hockey Blocks\", \"Penalty Minutes\", \"Shots\"],\n",
    "                                   \"Goalie\":[\"Saves\", \"Goals Against\"]}\n",
    "                           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gathering Daily Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NBA Statistics Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_nba_stats(day, month, year):\n",
    "    \"\"\"A function that will return a cleaned pandas dataframe of daily NBA statistics for BOTH players and teams that played on the \n",
    "       given day.\n",
    "       NOTE: All of day, month and year must be supplied as ints! \n",
    "       NOTE: This function can only be used for singular days, or the matching of location and opponent at the end of team data collection will return multiple/differing results, not singular locations and opponents!\n",
    "       Returns: A dictionary with three keys of 'Players', 'Goalies', and 'Teams'\"\"\"\n",
    "    \n",
    "    # if \"{}/{}/{}\".format(year, month, day) not in playing dates:\n",
    "    #     return pd.DataFrame()\n",
    "    \n",
    "    # We will eventually return this df\n",
    "    final_stats = pd.DataFrame()\n",
    "    final_team_df = pd.DataFrame()\n",
    "\n",
    "    # We will continue taking dates in intigers for consistiency. However, when scraping directly from Hockey Reference, dates will be supplied back as strings. \n",
    "    # For slicing purposes, we build our date into a correctly formatted string.\n",
    "    given_date = str(year).zfill(2) + \"-\" + str(month).zfill(2) + \"-\" + str(day).zfill(2)\n",
    "    url_date = str(year).zfill(2) + \"-\" + str(month).zfill(2) + \"-\" + str(day).zfill(2)\n",
    "    \n",
    "    # Now using pandas read_html, scrape  the title info for all nhl games during the season, and slice just the ones for the given date\n",
    "    season = str(int(find_nhl_season(day, month, year))) #WRITE A NEW FUNCTION THAT USES FINAL NBA SEASON DATES\n",
    "    all_nbl_games_url = \"https://www.basketball-reference.com/leagues/NBA_{}_games.html\".format(season)\n",
    "    webpage = requests.get(all_nbl_games_url)\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    months = [x.text.lower() for x in soup.find_all(\"div\", {\"class\":\"filter\"})[0].find_all('a')]\n",
    "    all_nba_games = pd.DataFrame()\n",
    "    for month in months:\n",
    "        month_url = \"https://www.basketball-reference.com/leagues/NBA_{}_games-{}.html\".format(season, month)\n",
    "        monthly_games_df = pd.read_html(month_url)[0]\n",
    "        all_nba_games = all_nba_games.append(monthly_games_df)\n",
    "       \n",
    "    all_nba_games.Date = all_nba_games.Date.apply(lambda x: datetime.strptime(x, \"%a, %b %d, %Y\").strftime(\"%Y-%m-%d\"))\n",
    "    relevant_nba_games = all_nba_games[all_nba_games.Date == given_date]\n",
    "  \n",
    "    \n",
    "    # If there were no games played on the given day, the df will be empty, and throw an error if we don't break before the next section\n",
    "    if len(relevant_nba_games) <= 0:\n",
    "        return pd.DataFrame()\n",
    "    else:\n",
    "        # Next, we build the url for the specific hockey reference url using data from each game in relevant_nhl_games\n",
    "        for game in range(len(relevant_nba_games)):\n",
    "            \n",
    "            eventual_away_table_num = 9 if relevant_nba_games[\"Unnamed: 7\"].iloc[game] == \"OT\" else 8\n",
    "            \n",
    "            home_team = relevant_nba_games[\"Home/Neutral\"].iloc[game]\n",
    "            home_abbr = nba_name_conversions[nba_name_conversions[\"Team Name\"] == home_team][\"Team Abbreviation\"].iloc[0]\n",
    "            away_team = relevant_nba_games[\"Visitor/Neutral\"].iloc[game]\n",
    "            away_abbr = nba_name_conversions[nba_name_conversions[\"Team Name\"] == away_team][\"Team Abbreviation\"].iloc[0]\n",
    "            \n",
    "            url_insert = \"\".join(url_date.split(\"-\")) + \"0\" + home_abbr\n",
    "            game_url = \"https://www.basketball-reference.com/boxscores/\" + url_insert + \".html\"\n",
    "    \n",
    "            time.sleep(5)\n",
    "            game_tables = pd.read_html(game_url, header=1)\n",
    "            \n",
    "            away_stats = game_tables[0]\n",
    "            away_stats = away_stats[(away_stats.Starters != \"Reserves\") & (pd.isna(away_stats.MP) == False)]\n",
    "            away_totals = away_stats[away_stats.Starters == \"Team Totals\"]\n",
    "            away_stats = away_stats[away_stats.Starters != \"Team Totals\"]\n",
    "            away_stats[\"team\"] = away_abbr\n",
    "            \n",
    "            home_stats = game_tables[eventual_away_table_num]\n",
    "            home_stats = home_stats[(home_stats.Starters != \"Reserves\") & (pd.isna(home_stats.MP) == False)]\n",
    "            home_totals = home_stats[home_stats.Starters == \"Team Totals\"]\n",
    "            home_stats = home_stats[home_stats.Starters != \"Team Totals\"]\n",
    "            home_stats[\"team\"] = home_abbr\n",
    "            \n",
    "            \n",
    "            home_totals[\"team\"] = home_abbr\n",
    "            away_totals[\"opponent\"] = home_abbr\n",
    "            \n",
    "            home_totals[\"opponent\"] = away_abbr\n",
    "            away_totals[\"team\"] = away_abbr\n",
    "            \n",
    "            home_points = home_totals.PTS.iloc[0]\n",
    "            away_points = away_totals.PTS.iloc[0]\n",
    "        \n",
    "            home_totals[\"PTS\"] = home_points\n",
    "            away_totals[\"PTS\"] = away_points\n",
    "            \n",
    "            home_totals[\"is_win\"] = 1 if home_points > away_points else 0\n",
    "            away_totals[\"is_win\"] = 1 if away_points > home_points else 0\n",
    "\n",
    "            webpage = requests.get(game_url)\n",
    "            soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "            \n",
    "            home_ids = [z[\"data-append-csv\"] for z in [y for y in [x for x in soup.find_all(\"table\") if \"csk\" in str(x)][eventual_away_table_num].find_all(\"th\") if \"csk\" in str(y)]]\n",
    "            away_ids = [z[\"data-append-csv\"] for z in [y for y in [x for x in soup.find_all(\"table\") if \"csk\" in str(x)][0].find_all(\"th\") if \"csk\" in str(y)]]\n",
    "           \n",
    "            home_stats[\"id\"] = home_ids\n",
    "            home_stats = home_stats[(home_stats.MP != \"Did Not Dress\") & (home_stats.MP != \"Not With Team\") & (home_stats.MP != \"Did Not Play\") & (home_stats.MP != \"Player Suspended\") & (pd.isna(home_stats.MP) == False)]\n",
    "            \n",
    "            away_stats[\"id\"] = away_ids\n",
    "            away_stats = away_stats[(away_stats.MP != \"Did Not Dress\") & (away_stats.MP != \"Not With Team\") & (away_stats.MP != \"Did Not Play\") & (away_stats.MP != \"Player Suspended\") & (pd.isna(away_stats.MP) == False)]\n",
    "            \n",
    "            stats_addition = home_stats.append(away_stats)\n",
    "            final_stats = final_stats.append(stats_addition).reset_index(drop=True)\n",
    "            \n",
    "            team_totals = home_totals.append(away_totals)\n",
    "            final_team_df = final_team_df.append(team_totals).reset_index(drop = True)\n",
    "            \n",
    "    final_stats.MP = final_stats.MP.apply(lambda x: float(x.split(\":\")[0]) + float(x.split(\":\")[1])/60)\n",
    "    #final_stats.PTS = final_stats.MP.apply(lambda x: int(x))\n",
    "    \n",
    "    final_team_df.PTS = final_team_df.PTS.apply(lambda x: int(x))\n",
    "    #final_team_df.MP = final_team_df.MP.apply(lambda x: float(x[\"players\"][\"MP\"].iloc[0].split(\":\")[0]) + float(x[\"players\"][\"MP\"].iloc[0].split(\":\")[1])/60)\n",
    "    \n",
    "    return {\"players\":final_stats, \"teams\":final_team_df, \"date\":given_date}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NHL Stats Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_nhl_stats(day, month, year):\n",
    "    \"\"\"A function that will return a cleaned pandas dataframe of daily NHL statistics for BOTH players and teams that played on the \n",
    "       given day.\n",
    "       NOTE: All of day, month and year must be supplied as ints! \n",
    "       NOTE: This function can only be used for singular days, or the matching of location and opponent at the end of team data collection will return multiple/differing results, not singular locations and opponents!\n",
    "       Returns: A dictionary with three keys of 'Players', 'Goalies', and 'Teams'\"\"\"\n",
    "    \n",
    "    def pull_hits_and_blocks(player, stat, location):\n",
    "        if location == \"home\":\n",
    "            try:\n",
    "                ans = home_advanced_stats[home_advanced_stats.Player == player][stat].iloc[0]\n",
    "            except:\n",
    "                return 0\n",
    "        else:\n",
    "            try: \n",
    "                ans = away_advanced_stats[away_advanced_stats.Player == player][stat].iloc[0]\n",
    "            except:\n",
    "                return 0\n",
    "            \n",
    "        return ans\n",
    "\n",
    "                \n",
    "    # if \"{}/{}/{}\".format(year, month, day) not in playing dates:\n",
    "    #     return pd.DataFrame()\n",
    "    \n",
    "    # We will eventually return this df\n",
    "    final_skater_df = pd.DataFrame()\n",
    "    final_goalie_df = pd.DataFrame()\n",
    "    final_team_df = pd.DataFrame()\n",
    "    final_penalty_df = pd.DataFrame()\n",
    "\n",
    "    # We will continue taking dates in intigers for consistiency. However, when scraping directly from Hockey Reference, dates will be supplied back as strings. \n",
    "    # For slicing purposes, we build our date into a correctly formatted string.\n",
    "    given_date = str(year).zfill(2) + \"-\" + str(month).zfill(2) + \"-\" + str(day).zfill(2)\n",
    "    \n",
    "    # Now using pandas read_html, scrape  the title info for all nhl games during the season, and slice just the ones for the given date\n",
    "    season = find_nhl_season(day, month, year)\n",
    "    all_nhl_games_url = \"https://www.hockey-reference.com/leagues/NHL_{}_games.html\".format(season)\n",
    "    all_nhl_games = pd.read_html(all_nhl_games_url)[0]\n",
    "    try:\n",
    "        playoff_games = pd.read_html(all_nhl_games_url)[1]\n",
    "        all_nhl_games = all_nhl_games.append(playoff_games)\n",
    "    except:\n",
    "        None\n",
    "    \n",
    "    all_nhl_games = all_nhl_games.rename(columns = {\"Date\":\"date\", \"Visitor\":\"visitor\", \"G\":\"away_goals\",\n",
    "                                                                            \"Home\":\"home\", \"G.1\":\"home_goals\", \"Unnamed: 5\":\"is_ot\",\n",
    "                                                                         \"Att.\":\"attendance\", \"LOG\":\"game_length\", \"Notes\":\"notes\"})\n",
    "    \n",
    "    relevant_nhl_games = all_nhl_games[all_nhl_games.date == given_date]\n",
    "\n",
    "    # If there were no games played on the given day, the df will be empty, and throw an error if we don't break before the next section\n",
    "    if len(relevant_nhl_games) <= 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # Next, we build the url for the specific hockey reference url using data from each game in relevant_nhl_games\n",
    "        for game in range(len(relevant_nhl_games)):\n",
    "            time.sleep(6)\n",
    "            home_team = relevant_nhl_games.home.iloc[game]\n",
    "            home_abbr = nhl_name_conversions[nhl_name_conversions[\"Team Name\"] == home_team][\"Team Abbreviation\"].iloc[0]\n",
    "            away_team = relevant_nhl_games.visitor.iloc[game]\n",
    "            away_abbr = nhl_name_conversions[nhl_name_conversions[\"Team Name\"] == away_team][\"Team Abbreviation\"].iloc[0]\n",
    "            \n",
    "            url_insert = \"\".join(given_date.split(\"-\")) + \"0\" + home_abbr\n",
    "            game_url = \"https://www.hockey-reference.com/boxscores/\" + url_insert + \".html\"\n",
    "            \n",
    "            \n",
    "            # Using the built url, scrape Hockey Reference and grab the tables (we know the order of them) for home and away\n",
    "            # Stats for both skaters and goalies\n",
    "            game_tables = pd.read_html(game_url, header=1)\n",
    "        \n",
    "            home_skater_stats = game_tables[4].drop(columns = \"Rk\")\n",
    "            home_skater_stats[\"team\"] = home_abbr\n",
    "            \n",
    "            home_goalie_stats = game_tables[5].drop(columns = \"Rk\")\n",
    "            home_goalie_stats[\"team\"] = home_abbr\n",
    "            \n",
    "            away_skater_stats = game_tables[2].drop(columns = \"Rk\")\n",
    "            away_skater_stats[\"team\"] = away_abbr\n",
    "            \n",
    "            away_goalie_stats = game_tables[3].drop(columns = \"Rk\")\n",
    "            away_goalie_stats[\"team\"] = away_abbr\n",
    "            \n",
    "            # Get and insert Pro Baseball Reference IDs into the stats dfs\n",
    "            webpage = requests.get(game_url)\n",
    "            soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "            \n",
    "            \n",
    "            away_names = [j.split(\",\")[1] + \" \" + j.split(\",\")[0] for j in [str(z).split(\"csk\")[2].split('\" ')[0].split(\"=\")[1].strip('\"') for z in [y for y in [x for x in soup.find_all(\"table\") if \"csk\" in str(x)][0].find_all(\"tr\") if \"csk\" in str(y)]]]\n",
    "            away_ids = [str(z).split(\"data-append-csv\")[1].split(\" \")[0].split(\"=\")[1].strip('\"') for z in [y for y in [x for x in soup.find_all(\"table\") if \"csk\" in str(x)][0].find_all(\"tr\") if \"csk\" in str(y)]]\n",
    "            home_names = [j.split(\",\")[1] + \" \" + j.split(\",\")[0] for j in [str(z).split(\"csk\")[2].split('\" ')[0].split(\"=\")[1].strip('\"') for z in [y for y in [x for x in soup.find_all(\"table\") if \"csk\" in str(x)][2].find_all(\"tr\") if \"csk\" in str(y)]]]\n",
    "            home_ids = [str(z).split(\"data-append-csv\")[1].split(\" \")[0].split(\"=\")[1].strip('\"') for z in [y for y in [x for x in soup.find_all(\"table\") if \"csk\" in str(x)][2].find_all(\"tr\") if \"csk\" in str(y)]]\n",
    "            \n",
    "            away_id_dict = {away_names[n]:away_ids[n] for n in range(len(away_names))}\n",
    "            home_id_dict = {home_names[n]:home_ids[n] for n in range(len(home_names))}\n",
    "            \n",
    "            home_skater_stats[\"player_id\"] = home_skater_stats.Player.apply(lambda x: home_id_dict[x] if x not in [\"TOTAL\", \"Empty Net\"] else \"\")\n",
    "            home_goalie_stats[\"player_id\"] = home_goalie_stats.Player.apply(lambda x: home_id_dict[x] if x not in [\"TOTAL\", \"Empty Net\"] else \"\")\n",
    "            #home_goalie_stats[\"goals_against\"] = home_goalie_stats.SA - home_goalie_stats.SV\n",
    "            \n",
    "            away_skater_stats[\"player_id\"] = away_skater_stats.Player.apply(lambda x: away_id_dict[x] if x not in [\"TOTAL\", \"Empty Net\"] else \"\")\n",
    "            away_goalie_stats[\"player_id\"] = away_goalie_stats.Player.apply(lambda x: away_id_dict[x] if x not in [\"TOTAL\", \"Empty Net\"] else \"\")\n",
    "            #away_goalie_stats[\"goals_against\"] = away_goalie_stats.SA - away_goalie_stats.SV\n",
    "            \n",
    "            \n",
    "            # Add home and away goals scored to later determine which team won\n",
    "            home_skater_stats[\"team_goals_scored\"] = home_skater_stats[home_skater_stats.Player == \"TOTAL\"].G.sum()\n",
    "            away_skater_stats[\"team_goals_scored\"] = away_skater_stats[away_skater_stats.Player == \"TOTAL\"].G.sum()\n",
    "            \n",
    "            home_skater_stats[\"team_goals_allowed\"] = away_skater_stats[away_skater_stats.Player == \"TOTAL\"].G.sum()\n",
    "            away_skater_stats[\"team_goals_allowed\"] = home_skater_stats[home_skater_stats.Player == \"TOTAL\"].G.sum()\n",
    "            \n",
    "            \n",
    "            # Grab the advanced stats table to later get hits and blocks\n",
    "            advanced_game_tables = pd.read_html(game_url)\n",
    "            \n",
    "            home_advanced_stats = advanced_game_tables[13]\n",
    "            home_advanced_stats[\"team\"] = home_abbr\n",
    "            \n",
    "            \n",
    "            away_advanced_stats = advanced_game_tables[6]\n",
    "            away_advanced_stats[\"team\"] = away_abbr\n",
    "            \n",
    "            # Pull hits and blocks data from a seperate table grabbed above\n",
    "            home_skater_stats[\"hits\"] = home_skater_stats.apply(lambda x: pull_hits_and_blocks(x.Player, \"HIT\", \"home\"), axis = 1)\n",
    "            home_skater_stats[\"blocks\"] = home_skater_stats.apply(lambda x: pull_hits_and_blocks(x.Player, \"BLK\", \"home\"), axis = 1)\n",
    "            \n",
    "            \n",
    "            away_skater_stats[\"hits\"] = away_skater_stats.apply(lambda x: pull_hits_and_blocks(x.Player, \"HIT\", \"away\"), axis = 1)\n",
    "            away_skater_stats[\"blocks\"] = away_skater_stats.apply(lambda x: pull_hits_and_blocks(x.Player, \"BLK\", \"away\"), axis = 1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Now that we have the stats from the game for both home and away skaters and goalies, we can add them game by game (in the loop)\n",
    "            # to our final tables and rename them as needed\n",
    "            skater_addition = pd.concat([home_skater_stats, away_skater_stats])\n",
    "            final_skater_df = final_skater_df.append(skater_addition).reset_index(drop=True)\n",
    "            \n",
    "            goalie_addition = pd.concat([home_goalie_stats, away_goalie_stats])\n",
    "            final_goalie_df = final_goalie_df.append(goalie_addition)\n",
    "            \n",
    "            # Now grab penalty data\n",
    "            penalty_table = pd.read_html(game_url)[1]\n",
    "            penalty_table.columns = [\"time\", \"team\", \"player\",\"penalty\",\"penalty_minutes\"]\n",
    "            \n",
    "            \n",
    "#             .rename(columns = {\"1st Period\": \"time\", \"1st Period.1\": \"team\", \"1st Period.2\":\"player\",\n",
    "#                                                                         \"1st Period.3\": \"penalty\", \"1st Period.4\":\"penalty_minutes\"})\n",
    "            \n",
    "            penalty_table = penalty_table[penalty_table.player.str.contains(\"Period\") == False].drop(columns=[\"time\"])\n",
    "            final_penalty_df = final_penalty_df.append(penalty_table)\n",
    "            \n",
    "    \n",
    "            \n",
    "               \n",
    "    \n",
    "    # Finally, after adding together all the night's games' stats, we can make final visual edits to the tables, and add columns for some extra stats\n",
    "    final_skater_df = final_skater_df.rename(columns = {\"Player\":\"player\", \"G\":\"goals\", \"A\": \"assists\", \"PTS\":\"points\", \"+/-\":\"plus_minus\",\n",
    "                                                        \"PIM\": \"penalty_minutes\", \"EV\":\"even_strength_goals\", \"PP\":\"power_play_goals\",\n",
    "                                                        \"SH\":\"short_handed_goals\", \"GW\":\"game_winning_goals\", \"EV.1\":\"even_strength_assists\",\n",
    "                                                         \"PP.1\":\"power_play_assists\", \"SH.1\": \"short_handed_assists\", \"S\":\"shots\", \"TOI\":\"time_on_ice\"})\n",
    "    final_skater_df[\"power_play_points\"] = final_skater_df.power_play_goals + final_skater_df.power_play_assists\n",
    "    final_skater_df[\"short_handed_points\"] = final_skater_df.short_handed_goals + final_skater_df.short_handed_assists\n",
    "    final_skater_df[\"time_on_ice\"] = final_skater_df[\"time_on_ice\"].apply(lambda x: float(x.split(\":\")[0]) + float(x.split(\":\")[1])/60 if pd.isna(x) == False else 0)\n",
    "    final_skater_df = final_skater_df[['player', 'goals', 'assists', 'points', \"power_play_points\", \"short_handed_points\"] + [x for x in final_skater_df if x not in ['player', 'goals', 'assists', 'points', \"power_play_points\", \"short_handed_points\"]]]\n",
    "    \n",
    "    final_goalie_df = final_goalie_df.rename(columns = {\"Player\":\"player\", \"DEC\":\"decision\", \"GA\":\"goals_against\", \"SA\":\"shots_against\",\n",
    "                                                        \"SV\":\"saves\", \"SV%\":\"save_percentage\", \"SO\":\"shutouts\", \"PIM\":\"penalty_minutes\",\n",
    "                                                        \"TOI\":\"time_on_ice\"})\n",
    "    final_goalie_df[\"time_on_ice\"] = final_goalie_df[\"time_on_ice\"].apply(lambda x: float(x.split(\":\")[0]) + float(x.split(\":\")[1])/60 if pd.isna(x) == False else 0)\n",
    "    \n",
    "    # As one last check, the scraping from Hockey Reference relies on the tables being in the right order. If they ever switch, the rename wont catch\n",
    "    # this, it will fail, and we know to grab a different numbered table from the website for home, away skater stats\n",
    "    correct_table_check = final_skater_df[\"power_play_goals\"]\n",
    "    \n",
    "    \n",
    "    # Now that we have skater and goalie stats for the home and away team finalized, grab team stats from rows titled \"TOTAL\"\n",
    "    team_stats = final_skater_df[final_skater_df.player == \"TOTAL\"].dropna(axis=1).reset_index(drop=True).drop(columns = [\"player\", \"time_on_ice\"])\n",
    "    team_stats = team_stats[[\"team\"] + [x for x in team_stats if x not in [\"team\"]]]\n",
    "    \n",
    "    final_skater_df = final_skater_df[final_skater_df.player != \"TOTAL\"]\n",
    "    final_goalie_df = final_goalie_df[final_goalie_df.player != \"TOTAL\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return {\"Skaters\":final_skater_df, \"Goalies\":final_goalie_df, \"Teams\":team_stats, \"Penalties\":final_penalty_df, \"date\":given_date}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NFL Stats Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_nfl_stats(day, month, year):\n",
    "    \"\"\"A function that will return a cleaned pandas dataframe of daily NFL statistics for BOTH players and teams that played on the \n",
    "       given day.\n",
    "       NOTE: All of day, month and year must be supplied as ints! \n",
    "       NOTE: This function can only be used for singular days, or the matching of location and opponent at the end of team data collection will return multiple/differing results, not singular locations and opponents!\n",
    "       \"\"\" \n",
    "    \n",
    "    # if \"{}/{}/{}\".format(year, month, day) not in playing dates:\n",
    "    #     return pd.DataFrame()\n",
    "    \n",
    "    # We will eventually return this df\n",
    "    final_offensive_df = pd.DataFrame()\n",
    "    final_kicking_df = pd.DataFrame()\n",
    "    final_defensive_df = pd.DataFrame()\n",
    "    final_team_df = pd.DataFrame()\n",
    "    final_snap_counts_df = pd.DataFrame()\n",
    "    final_field_goal_df = pd.DataFrame()\n",
    "    final_returns_df = pd.DataFrame()\n",
    "    final_penalty_df = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    # We will continue taking dates in intigers for consistiency. However, when scraping directly from Football Reference, dates will be supplied back as strings. \n",
    "    # For slicing purposes, we build our date into a correctly formatted string.\n",
    "    given_date = str(year).zfill(2) + \"-\" + str(month).zfill(2) + \"-\" + str(day).zfill(2)\n",
    "    \n",
    "    # Now using pandas read_html, scrape  the title info for all nfl games during the season, and slice just the ones for the given date\n",
    "    all_nfl_games_url = \"https://www.pro-football-reference.com/years/2022/games.htm\"\n",
    "    all_nfl_games = pd.read_html(all_nfl_games_url)[0].rename(columns = {\"Date\":\"date\", \"Week\":\"week\", \"Day\":\"day\", \"Time\":\"time\", \"Winner/tie\":\"winner/tie\", \"Loser/tie\":\"loser/tie\", \"PtsW\":\"winning_team_points\",\n",
    "                                                                     \"PtsL\":\"losing_team_points\", \"YdsW\":\"winning_team_yards\", \"TOW\":\"winning_team_turnovers\", \"YdsL\":\"losing_team_yards\", \"TOL\":\"losing_team_turnovers\"})\n",
    "    relevant_nfl_games = all_nfl_games[all_nfl_games.date == given_date]\n",
    "    \n",
    "    # If there were no games played on the given day, the df will be empty, and throw an error if we don't break before the next section\n",
    "    if len(relevant_nfl_games) <= 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # Next, we build the url for the specific hockey reference url using data from each game in relevant_nhl_games\n",
    "        for game in range(len(relevant_nfl_games)):\n",
    "            time.sleep(6)\n",
    "            \n",
    "            winning_team = relevant_nfl_games[\"winner/tie\"].iloc[game]\n",
    "            winning_abbr = nfl_name_conversions[nfl_name_conversions[\"Team Name\"] == winning_team][\"Team Abbreviation\"].iloc[0]\n",
    "            losing_team = relevant_nfl_games[\"loser/tie\"].iloc[game]\n",
    "            losing_abbr = nfl_name_conversions[nfl_name_conversions[\"Team Name\"] == losing_team][\"Team Abbreviation\"].iloc[0]\n",
    "            \n",
    "            # Account for the strange labeling of urls when there is a neutral site game like the SB or international\n",
    "            if relevant_nfl_games.iloc[game][\"Unnamed: 5\"] != \"N\":\n",
    "                url_key = winning_abbr if relevant_nfl_games.iloc[game][\"Unnamed: 5\"] != \"@\" else losing_abbr\n",
    "                url_insert = \"\".join(given_date.split(\"-\")) + \"0\" + url_key.lower()\n",
    "                game_url = \"https://www.pro-football-reference.com/boxscores/\" + url_insert + \".htm\"\n",
    "            \n",
    "            else:\n",
    "                webpage = requests.get(all_nfl_games_url)\n",
    "                soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "                date_insert = \"\".join(given_date.split(\"-\")) + \"0\"\n",
    "                game_possibilities = soup.find_all(\"td\", {\"data-stat\":\"boxscore_word\"})\n",
    "                games_on_date = [x for x in game_possibilities if date_insert in str(x)]\n",
    "                games_with_right_team = [x for x in games_on_date if winning_abbr.lower() in str(x) or losing_abbr.lower() in str(x)]\n",
    "                addition = games_with_right_team[0].a[\"href\"]\n",
    "                game_url = \"https://www.pro-football-reference.com\" + addition\n",
    " \n",
    "            \n",
    "            # Using the built url, scrape Football Reference and grab the tables (we know the order of them) for offensive, defensive, special teams and snap counts\n",
    "            game_tables = pd.read_html(game_url, header=1)\n",
    "        \n",
    "            \n",
    "            offensive_game_stats = game_tables[2].rename(columns = {\"Player\":\"player\", \"Tm\":\"team\", \"Cmp\":\"completions\", \"Att\":\"passing_attempts\", \"Yds\":\"passing_yards\", \"TD\":\"passing_touchdowns\", \n",
    "                                 \"Int\":\"interceptions\", \"Sk\":\"sacks_taken\", \"Yds.1\":\"sack_yards_taken\", \"Lng\":\"longest_pass\", \"Rate\":\"quaterback_rating\", \"Att.1\":\"rushing_attempts\",\n",
    "                                 \"Yds.2\":\"rushing_yards\", \"TD.1\":\"rushing_touchdowns\", \"Lng.1\":\"longest_rush\", \"Tgt\":\"targets\", \"Rec\":\"receptions\", \"Yds.3\":\"receiving_yards\",\n",
    "                                 \"TD.2\":\"receiving_touchdowns\", \"Lng.2\":\"longest_reception\", \"Fmb\":\"total_fumbles\", \"FL\":\"fumbles_lost\"}).dropna(subset = [\"player\"])\n",
    "            \n",
    "            offensive_game_stats = offensive_game_stats[offensive_game_stats.player != \"Player\"]\n",
    "            offensive_game_stats[\"passing_attempts\"] = offensive_game_stats[\"passing_attempts\"].apply(lambda x: int(x))\n",
    "            offensive_game_stats[\"rushing_attempts\"] = offensive_game_stats[\"rushing_attempts\"].apply(lambda x: int(x))\n",
    "            offensive_game_stats[\"receptions\"] = offensive_game_stats[\"receptions\"].apply(lambda x: int(x))\n",
    "            \n",
    "            point_tables = pd.read_html(game_url, header=0)\n",
    "            point_table = point_tables[1].iloc[-1].iloc[-2:]\n",
    "            offensive_game_stats[\"points_scored\"] = offensive_game_stats.team.apply(lambda x: point_table.loc[x])\n",
    "            offensive_game_stats[\"points_allowed\"] = offensive_game_stats.team.apply(lambda x: point_table[point_table.index!=x][0])\n",
    "            \n",
    "            # Get and insert offensive and kicking IDs\n",
    "            webpage = requests.get(game_url)\n",
    "            soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "            \n",
    "            offensive_ids = [str(x).split(\"data-append-csv=\")[1].split(\" \")[0].strip('\"') for x in soup.find_all(\"tr\") if \"data-append-csv\" in str(x)]\n",
    "            offensive_names = [x.a.text.strip() for x in soup.find_all(\"tr\") if \"data-append-csv\" in str(x)]\n",
    "            offensive_id_dict = {offensive_names[n]:offensive_ids[n] for n in range(len(offensive_names))}\n",
    "            offensive_game_stats[\"player_id\"] = offensive_game_stats.player.apply(lambda z: offensive_id_dict[z])\n",
    "            \n",
    "            \n",
    "            kicking_ids = [z.split('=\"')[1].split(\" \")[0].strip('\"') for z in [y for y in [x for x in soup.find_all(text=lambda text:isinstance(text, Comment)) if \"kick\" in str(x)] if \"data-append-csv\" in str(y)][1].split(\"data-append-csv\")[1:]]\n",
    "            kicking_names = [z.split(\"<\")[0].strip() for z in [y for y in [x for x in soup.find_all(text=lambda text:isinstance(text, Comment)) if \"kick\" in str(x)] if \"data-append-csv\" in str(y)][1].split('.htm\">')[1:]]\n",
    "            kicking_id_dict = {kicking_names[n]:kicking_ids[n] for n in range(len(kicking_names))}\n",
    "            \n",
    "            defense_ids = [y.split('\" ')[0].strip('\"') for y in str([x for x in soup.find_all(text=lambda text:isinstance(text, Comment)) if \"defense\" in str(x)]).split(\"data-append-csv=\")[1:]]\n",
    "            defense_names = [y.split(\"<\")[0].replace('\\\\', \"\").strip() for y in str([x for x in soup.find_all(text=lambda text:isinstance(text, Comment)) if \"defense\" in str(x)]).split('.htm\">')[1:]]\n",
    "            defense_id_dict = {defense_names[n]:defense_ids[n] for n in range(len(defense_names))}\n",
    "            \n",
    "            returns_ids = [y.split('\" ')[0].strip('\"') for y in str([x for x in soup.find_all(text=lambda text:isinstance(text, Comment)) if \"returns\" in str(x)]).split(\"data-append-csv=\")[1:]]\n",
    "            returns_names = [y.split(\"<\")[0].replace('\\\\', \"\").strip() for y in str([x for x in soup.find_all(text=lambda text:isinstance(text, Comment)) if \"returns\" in str(x)]).split('.htm\">')[1:]]\n",
    "            returns_id_dict = {returns_names[n]:returns_ids[n] for n in range(len(returns_names))}\n",
    "            \n",
    "            \n",
    "            # Make a table of all scored field goals and their distances from the pd.read_html. It doesn't really go with any category, but we'll need it for kicker scoring\n",
    "            # Note: we need to do a new read_html because the header level is different than the original one\n",
    "            scoring = pd.read_html(game_url, header=0)[1]\n",
    "            field_goals = scoring[(scoring.Detail.str.contains(\"field goal\") == True) & (scoring.Detail.str.contains(\"field goal return\") == False)]\n",
    "            field_goals[\"kicker\"] = field_goals.Detail.apply(lambda x: \" \".join(x.split(\"yard\")[0].split(\" \")[0:-2]))\n",
    "            field_goals[\"distance\"] = field_goals.Detail.apply(lambda x: (x.split(\"yard\")[0].split(\" \")[-2]))\n",
    "            field_goals[\"date\"] = str(month) + \"/\" + str(day) + \"/\" + str(year)\n",
    "            final_field_goals = field_goals[[\"kicker\", \"distance\", \"date\"]].copy()\n",
    "            final_field_goal_df = final_field_goal_df.append(final_field_goals)\n",
    "            \n",
    "            # Make a column for if the team won\n",
    "            offensive_game_stats[\"won\"] = offensive_game_stats.team.apply(lambda x: 1 if x==winning_abbr else 0)\n",
    "\n",
    "            # Make alterations to offensive stats - checking for division matchup, \n",
    "            teams = offensive_game_stats.team.unique()\n",
    "            divisions = [nfl_name_conversions[nfl_name_conversions[\"Team Code\"] == n][\"League\"].iloc[0] + nfl_name_conversions[nfl_name_conversions[\"Team Code\"] == n][\"Division\"].iloc[0] for n in teams]\n",
    "            offensive_game_stats[\"is_division_game\"] = 1 if len(set(divisions)) == 1 else 0\n",
    "            final_offensive_df = final_offensive_df.append(offensive_game_stats)\n",
    "            \n",
    "            \n",
    "            # Other than the straightforward offensive stats, the other tables (defensive, kicking, etc.) are all hidden in comments. We now take a secondary route to find them\n",
    "            scraped_html = requests.get(game_url)\n",
    "            soup = BeautifulSoup(scraped_html.content)\n",
    "\n",
    "            # Get all html comments, then filter out everything that isn't a table\n",
    "            comments = soup.find_all(text=lambda text:isinstance(text, Comment))\n",
    "            commented_out_tables = [BeautifulSoup(cmt).find_all('table') for cmt in comments]\n",
    "            \n",
    "            # Some of the entries in `commented_out_tables` are empty lists. Remove them.\n",
    "            commented_out_tables = [tab[0] for tab in commented_out_tables if len(tab) == 1]\n",
    "\n",
    "            # Go through the commented out tables pulling tables for kicking, defense, and snap counts, before altering titles and formatting to make them helpful\n",
    "            for table in commented_out_tables:\n",
    "\n",
    "                if table.get('id') == 'kicking':\n",
    "                    kicking_table = pd.read_html(str(table), header=1)[0].dropna(subset=[\"Tm\"]).rename(columns = {\"Player\":\"player\", \"Tm\":\"team\", \"XPM\":\"extra_points_made\", \"XPA\":\"extra_points_attempted\",\n",
    "                                                                                                                  \"FGM\":\"field_goals_made\", \"FGA\":\"field_goals_attempted\", \"Pnt\":\"punts\",\n",
    "                                                                                                                  \"Yds\":\"punt_yards\", \"Y/P\":\"yards_per_punt\", \"Lng\":\"longest_punt\"}).fillna(0)\n",
    "                    kicking_table = kicking_table[kicking_table.team != \"Tm\"]\n",
    "                    kicking_table[\"player_id\"] = kicking_table.player.apply(lambda x: kicking_id_dict[x])\n",
    "                    final_kicking_df = final_kicking_df.append(kicking_table)\n",
    "                    \n",
    "                if table.get(\"id\") == \"player_defense\":\n",
    "                    defense_table = pd.read_html(str(table), header=1)[0].dropna(subset=[\"Tm\"]).rename(columns = {\"Tm\":\"team\", \"Int\":\"interceptions\", \"Yds\":\"interception_return_yards\",\n",
    "                                                                                                      \"TD\":\"interception_touchdowns\", \"Lng\":\"longest_interception_return\",\n",
    "                                                                                                      \"Sk\":\"sacks\", \"Comb\":\"total_tackles\", \"TFL\":\"tackles_for_loss\",\n",
    "                                                                                                      \"QBHits\":\"qb_hits\", \"FR\":\"fumble_recoveries\", \"Yds.1\":\"fumble_return_yards\",\n",
    "                                                                                                      \"TD.1\":\"fumble_touchdowns\"}).drop(columns = [\"PD\", \"Solo\", \"Ast\", \"FF\"])\n",
    "                    defense_table = defense_table[defense_table.team != \"Tm\"]\n",
    "                    defense_table[\"player_id\"] = defense_table.Player.apply(lambda x: defense_id_dict[x])\n",
    "                    final_defensive_df = final_defensive_df.append(defense_table)\n",
    "                    \n",
    "                    \n",
    "                if table.get(\"id\") == \"returns\":\n",
    "                    returns_table = pd.read_html(str(table), header = 1)[0].dropna(subset=[\"Tm\"]).rename(columns = {\"Player\":\"player\", \"Tm\":\"team\", \"Yds\":\"kick_return_yards\", \"Yds.1\":\"punt_return_yards\",\n",
    "                                                                                                                    \"TD\":\"kick_return_touchdowns\", \"TD.1\":\"punt_return_touchdowns\"})\n",
    "                    \n",
    "                    returns_table = returns_table[returns_table.player != \"Player\"][[\"player\", \"team\", \"kick_return_yards\", \"kick_return_touchdowns\", \"punt_return_yards\", \"punt_return_touchdowns\"]]\n",
    "                    returns_table[\"player_id\"] = returns_table.player.apply(lambda x: returns_id_dict[x])\n",
    "                    final_returns_df = final_returns_df.append(returns_table)\n",
    "      \n",
    "                    \n",
    "                if table.get(\"id\") == \"team_stats\":\n",
    "                    team_stats_table = pd.read_html(str(table), header = 0)[0].rename(columns = {\"Unnamed: 0\":\"stat\"})\n",
    "                    penalty_yards = team_stats_table[team_stats_table.stat == \"Penalties-Yards\"].T.iloc[1:]\n",
    "                    penalty_yards = penalty_yards[penalty_yards.columns[0]].apply(lambda x: float(x.split(\"-\")[-1]))\n",
    "                    final_penalty_df = pd.concat([final_penalty_df, penalty_yards])\n",
    "                    \n",
    "                if table.get(\"id\") == \"home_snap_counts\" or table.get(\"id\") == \"vis_snap_counts\":\n",
    "                    location = table.get(\"id\")\n",
    "\n",
    "                    snaps = pd.read_html(str(table), header=1)[0].rename(columns = {\"Player\":\"player\", \"Num\":\"offensive_snaps\", \"Pct\":\"offensive_percent\", \"Num.1\":\"defensive_snaps\",\n",
    "                                                                                        \"Pct.1\":\"defensive_percent\", \"Num.2\":\"special_teams_snaps\", \"Pct.2\":\"special_teams_percent\"})\n",
    "\n",
    "                    snaps[\"total_offensive_snaps\"] = snaps.apply(lambda x: x.offensive_snaps * (100/float(x.offensive_percent.split(\"%\")[0])) if x.offensive_percent != \"0%\" else 0, axis=1)\n",
    "                    snaps[\"total_offensive_snaps\"] = round(snaps[snaps.offensive_snaps == max(snaps.offensive_snaps)].total_offensive_snaps.iloc[0])\n",
    "\n",
    "                    snaps[\"total_defensive_snaps\"] = snaps.apply(lambda x: x.defensive_snaps * (100/float(x.defensive_percent.split(\"%\")[0])) if x.defensive_percent != \"0%\" else 0, axis=1)\n",
    "                    snaps[\"total_defensive_snaps\"] = round(snaps[snaps.defensive_snaps == max(snaps.defensive_snaps)].total_defensive_snaps.iloc[0])\n",
    "\n",
    "                    snaps[\"total_special_teams_snaps\"] = snaps.apply(lambda x: x.special_teams_snaps * (100/float(x.special_teams_percent.split(\"%\")[0])) if x.special_teams_percent != \"0%\" else 0, axis=1)\n",
    "                    snaps[\"total_special_teams_snaps\"] = round(snaps[snaps.special_teams_snaps == max(snaps.special_teams_snaps)].total_special_teams_snaps.iloc[0])\n",
    "\n",
    "                    snaps = snaps.drop(columns = [\"Pos\", \"offensive_percent\", \"defensive_percent\", \"special_teams_percent\"])\n",
    "                    \n",
    "                    final_snap_counts_df = final_snap_counts_df.append(snaps)\n",
    "\n",
    "            final_field_goal_df[\"team\"] = final_field_goal_df.kicker.apply(lambda x: final_kicking_df[final_kicking_df.player == x].team.iloc[0])\n",
    "            \n",
    "    \n",
    "\n",
    "    return {\"Offense\":final_offensive_df.reset_index(drop=True), \"Defense\":final_defensive_df.reset_index(drop=True), \"Kicking\":final_kicking_df.reset_index(drop=True),\n",
    "            \"Snaps\":final_snap_counts_df.reset_index(drop=True), \"Field Goals\":final_field_goal_df.reset_index(drop=True), \"Returns\":final_returns_df.reset_index(drop=True),\n",
    "            \"Penalties\":final_penalty_df.rename(columns = {0:\"penalty_yards\"}).reset_index().rename(columns = {\"index\":\"team\"}), \"date\":given_date}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MLB Stats Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_mlb_stats(day, month, year):\n",
    "\n",
    "    \"\"\"A function that will return a cleaned pandas dataframe of daily MLB statistics for BOTH players and teams that played on the \n",
    "       given day.\n",
    "       NOTE: All of day, month and year must be supplied as ints! \n",
    "       NOTE: This function can only be used for singular days, or the matching of location and opponent at the end of team data collection will return multiple/differing results, not singular locations and opponents!\n",
    "       \"\"\" \n",
    "    def runs_allowed(row):\n",
    "        return team_batting[(team_batting.game_id == row.game_id) & (team_batting[\"Team Name\"] != row[\"Team Name\"])].R.iloc[0]\n",
    "    \n",
    "    # if \"{}/{}/{}\".format(year, month, day) not in playing dates:\n",
    "    #     return pd.DataFrame()\n",
    "    \n",
    "    given_date = str(year).zfill(2) + \"-\" + str(month).zfill(2) + \"-\" + str(day).zfill(2)\n",
    "    \n",
    "    dh_dict = {}\n",
    "    \n",
    "    # We will eventually return these dfs\n",
    "    final_batting_df = pd.DataFrame()\n",
    "    final_pitching_df = pd.DataFrame()\n",
    "    final_team_df = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    # Get all games played that day and their url inserts to be used in scraping baseball reference\n",
    "    games = Boxscores(datetime(year, month, day)).games[\"{}-{}-{}\".format(month, day, year)]\n",
    "    \n",
    "    for game in games:\n",
    "        time.sleep(6)\n",
    "        home_team = game[\"home_name\"]\n",
    "        \n",
    "        if home_team not in dh_dict:\n",
    "            dh_dict[home_team] = 1\n",
    "        url_insert = mlb_name_conversions[mlb_name_conversions[\"Team Name\"] == home_team][\"Fangraphs Insert\"].iloc[0]\n",
    "        url = \"https://www.fangraphs.com/boxscore.aspx?date={}&team={}&dh=0&season={}#home_standard\".format(given_date, url_insert, year)\n",
    "        \n",
    "        try:\n",
    "            tables = pd.read_html(url)\n",
    "        except:\n",
    "            try: \n",
    "                url = \"https://www.fangraphs.com/boxscore.aspx?date={}&team={}&dh={}&season={}#home_standard\".format(given_date, url_insert, dh_dict[home_team], year)\n",
    "                tables = pd.read_html(url)\n",
    "                dh_dict[home_team] += 1\n",
    "            except:\n",
    "                tables = pd.read_html(url)\n",
    "        \n",
    "        # Get and insert offensive and kicking IDs\n",
    "        webpage = requests.get(url)\n",
    "        soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "        \n",
    "        all_ids = [y[\"href\"].split(\"playerid=\")[1].split(\"&\")[0]for y in [item for sublist in [x.find_all(\"a\") for x in soup.find_all(\"table\", {\"class\":\"rgMasterTable\"})[0:4]] for item in sublist]]\n",
    "        all_names = [y.text for y in [item for sublist in [x.find_all(\"a\") for x in soup.find_all(\"table\", {\"class\":\"rgMasterTable\"})[0:4]] for item in sublist]]\n",
    "        \n",
    "        id_dict = {all_names[n]:all_ids[n] for n in range(len(all_names))}\n",
    "                \n",
    "        \n",
    "        # Get the basic info of the game like who played, how much they scored, and who won\n",
    "        game_info = tables[14]\n",
    "        home_team = game_info[0].iloc[2]\n",
    "        home_runs = int(game_info[game_info.columns[-1]].iloc[2])\n",
    "        away_team = game_info[0].iloc[1]\n",
    "        away_runs = int(game_info[game_info.columns[-1]].iloc[1])\n",
    "        winner = home_team if home_runs > away_runs else away_team\n",
    "        innings = int(game_info.columns[0]) - 1\n",
    "        \n",
    "        game_id = home_team + str(home_runs) + away_team + str(away_runs) + given_date\n",
    "        \n",
    "        # Get the raw batting and pitching tables from the game\n",
    "        home_batting = tables[27]\n",
    "        home_pitching = tables[28]\n",
    "        \n",
    "        away_batting = tables[29]\n",
    "        away_pitching = tables[30]\n",
    "        \n",
    "        \n",
    "        # Combine the home and away stats for both batting and pitching\n",
    "        home_batting[\"Team Name\"] = home_team\n",
    "        away_batting[\"Team Name\"] = away_team\n",
    "        \n",
    "        home_pitching[\"Team Name\"] = home_team\n",
    "        away_pitching[\"Team Name\"] = away_team\n",
    "        \n",
    "        batting = home_batting.append(away_batting)\n",
    "        pitching = home_pitching.append(away_pitching)\n",
    "        \n",
    "        \n",
    "        # Clean the batting tables before we append them to the final batting stats\n",
    "        team_batting = batting[batting.Name == \"Total\"]\n",
    "        player_batting = batting[batting.Name != \"Total\"]\n",
    "        \n",
    "        player_batting[\"total_bases\"] = player_batting[\"1B\"] + player_batting[\"2B\"] * 2 + player_batting[\"3B\"] * 3 + player_batting[\"HR\"] * 4\n",
    "        \n",
    "        player_batting[\"Position\"] = player_batting.Name.apply(lambda x: x.split(\" - \")[-1])\n",
    "        player_batting.Name = player_batting.Name.apply(lambda x: x.split(\" - \")[0])\n",
    "\n",
    "        player_batting[\"walks\"] = player_batting.BB + player_batting.IBB + player_batting.HBP\n",
    "        player_batting[\"sacrifices\"] = player_batting.SF + player_batting.SH\n",
    "        player_batting = player_batting.rename(columns = {\"Name\":\"name\", \"PA\":\"plate_appearences\", \"H\":\"hits\", \"R\":\"runs\", \"1B\":\"singles\", \"2B\":\"doubles\", \"3B\":\"triples\", \"HR\":\"home_runs\", \"RBI\":\"runs_batted_in\",\n",
    "                                                          \"SB\":\"stolen_bases\", \"SO\":\"strikeouts\"})\n",
    "        player_batting[\"game_id\"] = game_id\n",
    "        \n",
    "       \n",
    "        player_batting[\"player_id\"] = player_batting.name.apply(lambda x: id_dict[x])\n",
    "        \n",
    "        \n",
    "        # Clean the pitching tables before we append them to the final pitching stats\n",
    "        pitching.Name = pitching.Name.apply(lambda x: x.split(\" (\")[0])\n",
    "        \n",
    "                # Right now we are calculating team pitching stats because it's easy, but I'm not including it in the output bc we don't have any stats with it. \n",
    "                # However, if we want to include them one day, here is where they are.\n",
    "        team_pitching = pitching[pitching.Name == \"Total\"]\n",
    "        player_pitching = pitching[pitching.Name != \"Total\"]\n",
    "        \n",
    "        player_pitching = player_pitching.rename(columns = {\"Name\":\"name\", \"IP\":\"innings\", \"SV\":\"saves\", \"ER\":\"earned_runs\", \"SO\":\"Pitching Strikeouts\"})\n",
    "        player_pitching.innings = player_pitching.innings.apply(lambda x: float(str(x).split(\".\")[0] +\".\"+ str(int(str(x).split('.')[-1])/10*3.3).split(\".\")[-1]))\n",
    "        player_pitching[\"game_id\"] = game_id\n",
    "        \n",
    "        player_pitching[\"player_id\"] = player_pitching.name.apply(lambda x: id_dict[x])\n",
    "        \n",
    "        # Next remove all the pitchers from the batting stats so NL Pitchers don't get batting stats\n",
    "        pitchers_used = player_pitching.player_id\n",
    "        player_batting = player_batting[player_batting.player_id.isin(pitchers_used) == False]\n",
    "        \n",
    "        \n",
    "        # Clean the team tables before we append them to the final team stats\n",
    "        team_batting[\"game_id\"] = game_id\n",
    "        team_batting[\"runs_allowed\"] = team_batting.apply(lambda x: runs_allowed(x), axis = 1)\n",
    "        team_batting[\"win_loss\"] = team_batting.apply(lambda x: \"W\" if x.R > x.runs_allowed else \"L\", axis = 1)\n",
    "            \n",
    "        # Currently we assume all extra inning games are 10+ innings. If MLB keeps the double header rules then make sure to change to account for 8 inning extra inning games!!!\n",
    "        team_batting[\"is_extra_innings\"] = 1 if innings > 9 else 0\n",
    "        team_batting = team_batting.rename(columns = {\"Team Name\":\"team\", \"R\":\"runs_scored\"})\n",
    "        \n",
    "        \n",
    "        # Append the batting stats to the batting df and the picthing stats to the picthing df\n",
    "        final_batting_df = final_batting_df.append(player_batting)\n",
    "        final_pitching_df = final_pitching_df.append(player_pitching)\n",
    "                # If we ever want to include team pitching stats, below is where we can include team_picthing\n",
    "        final_team_df = final_team_df.append(team_batting)\n",
    "\n",
    "        \n",
    "        # Finally append the date to all dfs\n",
    "        final_batting_df[\"Date\"] = given_date\n",
    "        final_pitching_df[\"Date\"] = given_date\n",
    "        final_team_df['Date'] = given_date\n",
    "        \n",
    "        final_team_df = final_team_df[['team'] + [col for col in final_team_df.columns if col not in [\"team\", \"Name\"]]]\n",
    "        \n",
    "\n",
    "        \n",
    "    return {\"batters\":final_batting_df.reset_index(drop=True), \"pitchers\":final_pitching_df.reset_index(drop=True), \"teams\":final_team_df.reset_index(drop=True), \"date\":given_date}\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Transform Daily Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform NBA Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_nba_stats(nba):\n",
    "    if len(nba) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "\n",
    "    nba_stats = pd.DataFrame()\n",
    "    team_stats = pd.DataFrame()\n",
    "    \n",
    "    nba_data = nba[\"players\"]\n",
    "    team_data = nba[\"teams\"]\n",
    "    date = nba[\"date\"]\n",
    "    \n",
    "    # Build standard player stats\n",
    "    nba_stats[\"Name\"] = nba_data[\"Starters\"]\n",
    "    nba_stats[\"Team\"] = nba_data[\"team\"]\n",
    "    nba_stats[\"Points\"] = nba_data[\"PTS\"].apply(lambda x: int(x))\n",
    "    #nba_stats[\"field_goals_made\"] = nba_data[\"made_field_goals\"] \n",
    "    nba_stats[\"Three Pointers\"] = nba_data[\"3P\"].apply(lambda x: int(x))\n",
    "    nba_stats[\"Rebounds\"] = nba_data[\"TRB\"].apply(lambda x: int(x))\n",
    "    nba_stats[\"Minutes\"] = nba_data[\"MP\"].apply(lambda x: float(x))\n",
    "    nba_stats[\"Assists\"] = nba_data[\"AST\"].apply(lambda x: int(x))\n",
    "    nba_stats[\"Turnovers\"] = nba_data[\"TOV\"].apply(lambda x: int(x))\n",
    "    nba_stats[\"Blocks\"] = nba_data[\"BLK\"].apply(lambda x: int(x))\n",
    "    nba_stats['Steals'] = nba_data[\"STL\"].apply(lambda x: int(x))\n",
    "    nba_stats[\"Fouls\"] = nba_data[\"PF\"].apply(lambda x: int(x))\n",
    "    nba_stats[\"Player ID\"] = nba_data[\"id\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    nba_stats[\"Free Throws Made\"] = nba_data[\"FT\"].apply(lambda x: int(x))\n",
    "    nba_stats[\"Free Throw Percentage Denominator\"] = nba_data[\"FTA\"].apply(lambda x: int(x))\n",
    "    \n",
    "    \n",
    "    \n",
    "    nba_stats[\"teams_share_of_points_numerator\"] = nba_stats[\"Points\"].apply(lambda x: int(x))\n",
    "    nba_stats[\"teams_share_of_points_denominator\"] = nba_stats[\"Team\"].apply(lambda x: int(team_data[team_data.team == x].PTS.iloc[0]))\n",
    "    \n",
    "    \n",
    "    # Build standard team_stats\n",
    "    team_stats[\"Team\"] = team_data[\"team\"]\n",
    "    team_stats[\"Is Win\"] = team_data[\"is_win\"].apply(lambda x: True if x == 1 else False)\n",
    "    team_stats[\"Points Scored\"] = team_data[\"PTS\"].apply(lambda x: int(x))\n",
    "    team_stats[\"Points Allowed\"] = team_data.team.apply(lambda x: int(team_data[team_data.opponent == x].PTS.iloc[0]))\n",
    "    team_stats[\"Point Differential\"] = team_stats[\"Points Scored\"] - team_stats[\"Points Allowed\"]\n",
    "    team_stats = team_stats.drop(columns = [\"Points Scored\", \"Points Allowed\"])\n",
    "    #team_stats[\"players_fouled_out\"] = team_data[\"team\"].apply(lambda x: len(nba_data[(nba_data.team == x) & (nba_data.personal_fouls >= 6)]))\n",
    "    \n",
    "    ### WILL CALCULATE POINTS/SCORE WHEN ASSIGNING TO OWNERSHIP FOR DATES. WILL PUT ALL LISTS OF 8 HIGHEST MINS INTO ONE LIST, THEN CALCULATE THE STDEV\n",
    "    team_stats[\"Team Minutes Distribution\"] = team_data[\"team\"].apply(lambda x: [nba_stats[nba_stats.Team == x].sort_values(by = \"Minutes\").iloc[0:8]])\n",
    "    \n",
    "    \n",
    "    # Attatch the date to the dfs for easier reference later on\n",
    "    nba_stats[\"Date\"] = date\n",
    "    team_stats[\"date\"] = date\n",
    "    \n",
    "    # Fillna\n",
    "    nba_stats = nba_stats.fillna(0)\n",
    "    team_stats = team_stats.fillna(0)\n",
    "    \n",
    "    # Final filter down to just 2023 specific scoring categories\n",
    "    nba_stats = nba_stats[[\"Name\", \"Player ID\", \"Three Pointers\", \"Free Throws Made\", \"Rebounds\", \"Assists\", \"Steals\", \"Blocks\", \"Turnovers\", \"Points\", \"Date\"]]\n",
    "    \n",
    "    return {\"players\":nba_stats, \"teams\":team_stats}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform NHL Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_nhl_stats(nhl_data):\n",
    "    if len(nhl_data) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    goalie_data = nhl_data[\"Goalies\"]\n",
    "    skater_data = nhl_data[\"Skaters\"][nhl_data[\"Skaters\"].player.isin(goalie_data.player)==False]\n",
    "    player_data = skater_data.append(goalie_data).reset_index(drop=True)\n",
    "    team_data = nhl_data[\"Teams\"]\n",
    "    penalty_data = nhl_data[\"Penalties\"]\n",
    "    date = nhl_data[\"date\"]\n",
    "    \n",
    "    player_stats = pd.DataFrame()\n",
    "    team_stats = pd.DataFrame()\n",
    "    \n",
    "    # Build standard player stats\n",
    "    player_stats[\"Name\"] = player_data.player.reset_index(drop=True)\n",
    "    player_stats[\"Team\"] = player_data.team\n",
    "    player_stats[\"Goals\"] = player_data.goals\n",
    "    player_stats[\"Assists\"] = player_data.assists\n",
    "    player_stats[\"Hockey Points\"] = player_stats.Goals + player_stats.Assists\n",
    "    player_stats[\"Penalty Minutes\"] = player_data.penalty_minutes\n",
    "    player_stats[\"Shots\"] = player_data.shots\n",
    "    player_stats[\"Hockey Hits\"] = player_data.hits\n",
    "    player_stats[\"Hockey Blocks\"] = player_data.blocks\n",
    "    player_stats[\"Plus Minus\"] = player_data.plus_minus\n",
    "    player_stats[\"Power Play Points\"] = player_data.power_play_points\n",
    "    player_stats[\"Bench Minutes\"] = player_data.time_on_ice\n",
    "    player_stats[\"Fights\"] = player_data.player.apply(lambda x: len(penalty_data[(penalty_data.player == x) & (penalty_data.penalty == \"Fighting\")]))\n",
    "    player_stats[\"Goals Against\"] = player_data.goals_against.reset_index(drop = True) \n",
    "    player_stats[\"Shots Against\"] = player_data.shots_against\n",
    "    player_stats[\"Saves\"] = player_data.shots_against - player_data.goals_against\n",
    "    player_stats[\"Shutouts\"] = player_data.shutouts\n",
    "    player_stats[\"Player ID\"] = player_data.player_id\n",
    "    \n",
    "    # Build the standard team stats\n",
    "    team_stats[\"Team\"] = team_data.team\n",
    "    team_stats[\"Points\"] = team_data.points\n",
    "    team_stats[\"Goals Scored\"] = team_stats.Team.apply(lambda x: player_data[player_data.team == x].team_goals_scored.iloc[0])\n",
    "    team_stats[\"Goals Allowed\"] = team_stats.Team.apply(lambda x: player_data[player_data.team == x].team_goals_allowed.iloc[0])\n",
    "    team_stats[\"Is Win\"] = team_stats[\"Goals Scored\"] > team_stats[\"Goals Allowed\"]\n",
    "    team_stats = team_stats.drop(columns = [\"Goals Scored\", \"Goals Allowed\"])\n",
    "    \n",
    "    # Build the non-standard team stats\n",
    "    team_stats[\"Special Teams Strength Numerator\"] = team_data.power_play_goals + team_data.short_handed_goals\n",
    "    team_stats[\"Special Teams Strength Denominator\"] = team_data.goals\n",
    "    \n",
    "    \n",
    "    # Attatch the date to the dfs for easier reference later on\n",
    "    player_stats[\"Date\"] = date\n",
    "    team_stats[\"Date\"] = date\n",
    "    \n",
    "    player_stats = player_stats[player_stats.Name != \"Empty Net\"]\n",
    "    \n",
    "    # Fillna\n",
    "    player_stats = player_stats.fillna(0)\n",
    "    team_stats = team_stats.fillna(0)\n",
    "    \n",
    "    # Final filter down to just 2023 specific scoring categories\n",
    "    player_stats = player_stats[[\"Name\", \"Player ID\", \"Hockey Points\", \"Hockey Hits\", \"Hockey Blocks\", \"Penalty Minutes\", \"Shots\", \"Saves\", \"Goals Against\", \"Date\"]]\n",
    "    \n",
    "\n",
    "    \n",
    "    return {\"players\":player_stats, \"teams\":team_stats}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform NFL Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_nfl_stats(nfl_data):\n",
    "    if len(nfl_data) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Functions that will be necessary in transforming nfl stats\n",
    "    # def return_stats(player, stat):\n",
    "    #         try:\n",
    "    #             ans = return_data[return_data.Player == player][stat].iloc[0]\n",
    "    #             return float(ans)\n",
    "    #         except:\n",
    "    #             return 0\n",
    "            \n",
    "        \n",
    "    # Pull in the raw data from the get_daily_xxx_stats function and clean as necessary\n",
    "    offensive_data = nfl_data[\"Offense\"]\n",
    "    return_data = nfl_data[\"Returns\"]\n",
    "    offensive_data = offensive_data.join(return_data.set_index(\"player\"), on = \"player\",how = \"outer\", rsuffix = \"off\")\n",
    "    return_teams = offensive_data.teamoff\n",
    "    offensive_data.team.update(return_teams)\n",
    "    offensive_data = offensive_data.drop(columns = [\"teamoff\"])\n",
    "    \n",
    "    # Keep pulling in the raw data from the get_daily_xxx_stats function\n",
    "    defensive_data = nfl_data[\"Defense\"]\n",
    "    kicking_data = nfl_data[\"Kicking\"]\n",
    "    snaps_data = nfl_data[\"Snaps\"]\n",
    "    field_goal_data = nfl_data[\"Field Goals\"]\n",
    "    penalty_data = nfl_data[\"Penalties\"]\n",
    "    date = nfl_data[\"date\"]\n",
    "    \n",
    "    # Create dfs for data to end up in\n",
    "    offensive_stats = pd.DataFrame()\n",
    "    defensive_stats = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    # Convert numbers that need to be calculated on into ints from the strings they are now\n",
    "    for stat in [\"rushing_yards\", \"rushing_touchdowns\", \"receiving_yards\", \"receiving_touchdowns\", \"total_fumbles\", \"fumbles_lost\", \"sacks\", \"passing_yards\", \"passing_touchdowns\",\n",
    "                 \"interceptions\", \"fumble_recoveries\", \"interception_return_yards\", \"fumble_return_yards\"] + [\"kick_return_yards\", \"kick_return_touchdowns\", \"punt_return_yards\", \"punt_return_touchdowns\"]:\n",
    "        try:\n",
    "            offensive_data[stat] = offensive_data[stat].apply(lambda x: float(x))\n",
    "            defensive_data[stat] = defensive_data[stat].apply(lambda x: float(x))\n",
    "        except:\n",
    "            try:\n",
    "                offensive_data[stat] = offensive_data[stat].apply(lambda x: float(x))\n",
    "            except:\n",
    "                defensive_data[stat] = defensive_data[stat].apply(lambda x: float(x))\n",
    "                      \n",
    "    # Build standard offensive stats\n",
    "    offensive_stats[\"Name\"] = offensive_data.player\n",
    "    offensive_stats[\"Player ID\"] = offensive_data.player_id\n",
    "    offensive_stats[\"Team\"] = offensive_data.team\n",
    "    offensive_stats[\"All Purpose Yards\"] = offensive_data.rushing_yards * 1.05 + offensive_data.passing_yards * 0.27 + offensive_data.receiving_yards\n",
    "    offensive_stats[\"All Purpose TDs\"] = offensive_data.rushing_touchdowns * .95 + offensive_data.receiving_touchdowns + offensive_data.passing_touchdowns * 0.32\n",
    "    offensive_stats[\"Attempts\"] = offensive_data.passing_attempts * .18 + offensive_data.rushing_attempts * .42 + offensive_data.receptions\n",
    "\n",
    "    \n",
    "    # Build standard return stats\n",
    "    for return_stat in [\"kick_return_yards\", \"kick_return_touchdowns\", \"punt_return_yards\", \"punt_return_touchdowns\"]:\n",
    "        offensive_stats[return_stat] = offensive_data[return_stat]\n",
    "        \n",
    "        \n",
    "    offensive_stats[\"Return Yards\"] = offensive_stats.kick_return_yards + offensive_stats.punt_return_yards * 2.49\n",
    "    offensive_stats = offensive_stats.drop(columns = [\"kick_return_yards\", \"kick_return_touchdowns\", \"punt_return_yards\", \"punt_return_touchdowns\"])\n",
    "    \n",
    "    # Build standard defensive stats\n",
    "    defensive_stats[\"player\"] = defensive_data.team\n",
    "    defensive_stats[\"Player ID\"] = defensive_data.team\n",
    "    defensive_stats[\"Sacks/Turnovers\"] = defensive_data.sacks * 0.51 + defensive_data.interceptions + defensive_data.fumble_recoveries\n",
    "    defensive_stats = defensive_stats.groupby(by = \"Player ID\").sum()\n",
    "    \n",
    "    # Build standard kicking stats\n",
    "    kicking_data.punt_yards = kicking_data.punt_yards.apply(lambda x: float(x))\n",
    "    field_goal_data.distance = field_goal_data.distance.apply(lambda x: float(x))\n",
    "    punting_stats = pd.DataFrame()\n",
    "    placekicking_stats = pd.DataFrame()\n",
    "    \n",
    "    punting_stats[\"Name\"] = kicking_data[kicking_data.punt_yards >0].player.unique()\n",
    "    punting_stats[\"Player ID\"] = punting_stats.Name.apply(lambda x: kicking_data[kicking_data.player == x].player_id.iloc[0])\n",
    "    punting_stats[\"Team\"] = punting_stats.Name.apply(lambda x: kicking_data[kicking_data.player == x].team.iloc[0])\n",
    "    placekicking_stats[\"Name\"] = field_goal_data.kicker.unique()\n",
    "    placekicking_stats[\"Player ID\"] = placekicking_stats.Name.apply(lambda x: kicking_data[kicking_data.player == x].player_id.iloc[0])\n",
    "    placekicking_stats[\"Team\"] = placekicking_stats.Name.apply(lambda x: kicking_data[kicking_data.player == x].team.iloc[0])\n",
    "    \n",
    "    punting_stats[\"Punt Yards\"] = punting_stats.Name.apply(lambda x: kicking_data[kicking_data.player == x].punt_yards.sum())\n",
    "    placekicking_stats[\"Field Goal Yards\"] = placekicking_stats.Name.apply(lambda x: field_goal_data[field_goal_data.kicker == x].distance.sum())\n",
    "    total_kicking_stats = pd.concat([punting_stats, placekicking_stats])\n",
    "    total_kicking_stats[\"Punt Yards\"] = total_kicking_stats[\"Punt Yards\"].apply(lambda x: 0 if pd.isna(x) == True else x)\n",
    "    total_kicking_stats[\"Field Goal Yards\"] = total_kicking_stats[\"Field Goal Yards\"].apply(lambda x: 0 if pd.isna(x) == True else x)\n",
    "    total_kicking_stats[\"Kicking Yards\"] = total_kicking_stats[\"Punt Yards\"] * .4 + total_kicking_stats[\"Field Goal Yards\"]\n",
    "    total_kicking_stats = total_kicking_stats.drop(columns = [\"Punt Yards\", \"Field Goal Yards\"])  \n",
    "    \n",
    "    individual_stats = offensive_stats.append(total_kicking_stats)\n",
    "    \n",
    "    # Attatch the date to each df for easier reference later on\n",
    "    individual_stats[\"Date\"] = date\n",
    "    defensive_stats[\"Date\"] = date\n",
    "    \n",
    "    # Fillna\n",
    "    individual_stats = individual_stats.fillna(0)\n",
    "    defensive_stats = defensive_stats.fillna(0)\n",
    "    \n",
    "    # We are currently unable to assign kickers to a specific team\n",
    "    individual_stats.team = individual_stats.Team.apply(lambda x: \"Unknown\" if x == 0 else x)\n",
    "    \n",
    "    individual_stats = individual_stats.drop(columns = [\"Team\"])\n",
    "\n",
    "    \n",
    "    return {\"players\":individual_stats.reset_index(drop = True), \"teams\":defensive_stats.reset_index(drop = False)}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform MLB Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mlb_stats(mlb_data):\n",
    "    batting_data = mlb_data[\"batters\"]\n",
    "    pitching_data = mlb_data[\"pitchers\"]\n",
    "    team_data= mlb_data[\"teams\"]\n",
    "    date = mlb_data[\"date\"]\n",
    "    \n",
    "    batting_stats = pd.DataFrame()\n",
    "    pitching_stats = pd.DataFrame()\n",
    "    team_stats = pd.DataFrame()\n",
    "    \n",
    "    # Build standard batting_stats\n",
    "    batting_stats[\"Name\"] = batting_data.name\n",
    "    batting_stats[\"Plate Appearences\"] = batting_data.plate_appearences\n",
    "    batting_stats[\"Hits\"] = batting_data.hits\n",
    "    batting_stats[\"Walks\"] = batting_data.walks\n",
    "    batting_stats[\"Runs\"] = batting_data.runs\n",
    "    batting_stats[\"RBIs\"] = batting_data.runs_batted_in\n",
    "    batting_stats[\"XBH\"] = batting_data.doubles + batting_data.triples + batting_data.home_runs\n",
    "    batting_stats[\"Home Runs\"] = batting_data.home_runs\n",
    "    batting_stats[\"Stolen Bases\"] = batting_data.stolen_bases\n",
    "    batting_stats[\"Sacrifices\"] = batting_data.sacrifices\n",
    "    batting_stats[\"Strikeouts\"] = batting_data.strikeouts\n",
    "    batting_stats[\"Player ID\"] = batting_data.player_id.apply(lambda x: int(x))\n",
    "    batting_stats[\"Total Bases\"] = batting_data.total_bases\n",
    "    batting_stats[\"Date\"] = batting_data.Date\n",
    "   \n",
    "    \n",
    "    # Build the standard pitching stats\n",
    "    pitching_stats[\"Name\"] = pitching_data.name\n",
    "    pitching_stats[\"Innings\"] = pitching_data.innings.apply(lambda x: float(x))\n",
    "    pitching_stats[\"Saves\"] = pitching_data.saves\n",
    "    pitching_stats[\"Player ID\"] = pitching_data.player_id.apply(lambda x: int(x))\n",
    "    pitching_stats[\"Pitching Strikeouts\"] = pitching_data[\"Pitching Strikeouts\"].apply(lambda x: int(x))\n",
    "    pitching_stats[\"Date\"] = pitching_data.Date\n",
    "    \n",
    "    # Build the non-standard pitching stats\n",
    "    pitching_stats[\"Earned Runs\"] = pitching_data.earned_runs.apply(lambda x: int(x))\n",
    "    pitching_stats[\"ERA Denominator\"] = pitching_data.innings\n",
    "    \n",
    "\n",
    "    \n",
    "    # Build standard team stats\n",
    "    team_stats[\"Team\"] = team_data.team\n",
    "    team_stats[\"Is Win\"] = team_data.win_loss.apply(lambda x: True if x == \"W\" else False)\n",
    "    team_stats[\"Run Differential\"] = team_data.runs_scored - team_data.runs_allowed\n",
    "    team_stats[\"Is Extra Inning Game\"] = team_data.is_extra_innings.apply(lambda x: True if x == 1 else False)\n",
    "    \n",
    "    \n",
    "    # Combine the batting and pitching stats into one df for all players\n",
    "    player_stats = pd.concat([batting_stats, pitching_stats])\n",
    "    player_stats = player_stats.fillna(0)\n",
    "  \n",
    "    # Final Filer down to only 2023 specific scoring stats\n",
    "    player_stats = player_stats[[\"Name\", \"Player ID\", \"Runs\", \"Home Runs\", \"RBIs\", \"Stolen Bases\", \"Walks\", \"Strikeouts\", \"Total Bases\", \"Innings\", \"Earned Runs\", \"Pitching Strikeouts\", \"Saves\", \"Date\"]]\n",
    "    \n",
    "    \n",
    "    return {\"players\":player_stats, \"teams\":team_stats}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Waiver Wire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid_team(roster):\n",
    "    \"\"\" Given a roster and its players, checks that the team meets all requirements. Can be used in testing for completing a \n",
    "        waiver claim\"\"\"\n",
    "    \n",
    "    valid = True\n",
    "    \n",
    "    total_players = roster[roster.Position != \"Injured Reserve\"]\n",
    "    valid = False if len(total_players) != 29 else valid\n",
    "    \n",
    "    \n",
    "    # Check that each league has the correct number of players\n",
    "    mlb_players = roster[roster.League == \"MLB\"]\n",
    "    valid = False if len(mlb_players) != 10 else valid\n",
    "\n",
    "    \n",
    "    nfl_players = roster[roster.League == \"NFL\"]\n",
    "    valid = False if len(nfl_players) != 8 else valid\n",
    " \n",
    "    nhl_players = roster[roster.League == \"NHL\"]\n",
    "    valid = False if len(nhl_players) != 6 else valid\n",
    "    \n",
    "    nba_players = roster[roster.League == \"NBA\"]\n",
    "    valid = False if len(nba_players) != 5 else valid\n",
    "\n",
    "\n",
    "    # Check that each position within each league has the correct number of players\n",
    "    mlb_roster = roster[roster.League == \"MLB\"]\n",
    "    valid = False if len(mlb_roster[mlb_roster.Position == \"Pitcher\"]) != 2 else valid\n",
    "    valid = False if max([len(mlb_roster[mlb_roster.Position == x]) for x in [\"Catcher\", \"First Base\", \"Second Base\", \"Short Stop\", \"Third Base\", \"Short Stop\", \"Left Field\", \"Center Field\", \"Right Field\"]]) > 1 else valid\n",
    "    \n",
    "    nfl_roster = roster[roster.League == \"NFL\"]\n",
    "    valid = False if max([len(nfl_roster[nfl_roster.Position == x]) for x in [\"Quarterback\", \"Running Back\", \"Wide Receiver\", \"Tight End\", \"Kicker\", \"Punter\", \"Returner\", \"Defense\"]]) > 1 else valid\n",
    "    \n",
    "    nhl_roster = roster[roster.League == \"NHL\"]\n",
    "    valid = False if len(nhl_roster[nhl_roster.Position == \"Defenseman\"]) != 2 else valid\n",
    "    valid = False if max([len(nhl_roster[nhl_roster.Position == x]) for x in [\"Goalie\", \"Center\", \"Right Wing\", \"Left Wing\"]]) > 1 else valid\n",
    "    \n",
    "    nba_roster = roster[roster.League == \"NBA\"]\n",
    "    valid = False if max([len(nba_roster[nba_roster.Position == x]) for x in [\"Point Guard\", \"Shooting Guard\", \"Small Forward\", \"Power Forward\", \"Center\"]]) > 1 else valid\n",
    "    \n",
    "    valid = False if max([len(roster[roster.Position == x]) for x in [\"Injured Reserve\"]]) > 1 else valid\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def claim_id_checker(league, id_value, player_name):\n",
    "    league = \"mlb\" if league == \"MLB\" else \"nfl\" if league == \"NFL\" else \"nhl\" if league == \"NHL\" else \"NBA\" if league == \"NBA\" else \"Failure\"\n",
    "    if league == \"Failure\":\n",
    "        failure = \"Invalid League for Claim\"\n",
    "        return failure\n",
    "        \n",
    "    elif league == \"mlb\":\n",
    "        url = \"https://www.baseball-reference.com/players/{}/{}.shtml\".format(id_value[0], id_value)\n",
    "        \n",
    "    elif league == \"nfl\":\n",
    "        url = \"https://www.pro-football-reference.com/players/{}/{}.htm\".format(id_value[0], id_value)\n",
    "        \n",
    "    elif league == \"nhl\":\n",
    "        url = \"https://www.hockey-reference.com/players/{}/{}.html\".format(id_value[0], id_value)\n",
    "        \n",
    "    elif league == \"nba\":\n",
    "        url = \"https://www.basketball-reference.com/players/{}/{}.html\".format(id_value[0], id_value)\n",
    "  \n",
    "    webpage = requests.get(url)\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    valid_pickup_id_check = False if player_name not in str(soup.find(\"title\")) else True\n",
    "    claim_success = False if valid_pickup_id_check == False else True\n",
    "    failure = \"Invalid ID for Pickup Player\" if valid_pickup_id_check == False else \"Successful\"\n",
    "    \n",
    "    return failure\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_waivers(waiver_sheet_file_path):\n",
    "\n",
    "    all_current_rostered_players = pd.DataFrame()\n",
    "    current_rosters = {}\n",
    "    all_requested_waiver_claims = {}\n",
    "    injured_reserve_moves = {}\n",
    "    waiver_history = pd.DataFrame(columns = [\"Participant\", \"Action\"])\n",
    "    ir_waiver_history = pd.DataFrame(columns = [\"Participant\", \"Action\"])\n",
    "\n",
    "    for participant in waiver_participants:\n",
    "        waiver_claims = pd.read_excel(waiver_sheet_file_path, sheet_name = participant, header = 4)\n",
    "        current_roster = waiver_claims.iloc[:, 1:5]\n",
    "        all_current_rostered_players = all_current_rostered_players.append(current_roster)\n",
    "        current_rosters[participant] = current_roster\n",
    "\n",
    "        requested_waiver_claims = waiver_claims.iloc[0:15, 7:].dropna(how = \"all\")\n",
    "        all_requested_waiver_claims[participant] = requested_waiver_claims\n",
    "\n",
    "        injured_reserve_info = waiver_claims.iloc[17:, 6:]\n",
    "        injured_reserve_moves[participant] = injured_reserve_info.reset_index(drop = True)\n",
    "\n",
    "    # Determine the waiver priority, and cross reference with only the participants who made claims this cycle\n",
    "    participants_with_claims = [x for x in all_requested_waiver_claims if len(all_requested_waiver_claims[x]) > 0]\n",
    "    total_waiver_priority = [\"Arron\"] ## Actually Determine Waiver Priority Based on Last Weeks Standings\n",
    "    waiver_priority = [x for x in total_waiver_priority if x in participants_with_claims]\n",
    "\n",
    "    while max([len(all_requested_waiver_claims[x]) for x in waiver_priority], default = 0) > 0:\n",
    "        top_priority = waiver_priority[0]\n",
    "        claim = all_requested_waiver_claims[top_priority].iloc[0]\n",
    "        claim_success = True\n",
    "\n",
    "        # Check that there is an ID for both a pickup and a dropping player\n",
    "        ids = pd.Series([claim[\"ID.1\"], claim[\"ID.2\"]])\n",
    "        ids_check = True if len(ids[ids.isna() == False]) == 2 else False\n",
    "        claim_success = False if ids_check == False else claim_success\n",
    "        failure = \"Fewer than 2 IDs inputted in the transaction\" if ids_check == False else \"\"\n",
    "\n",
    "        # Check if the ID of the player requested to pickup is valid\n",
    "        id_check = claim_id_checker(claim[\"League.1\"], claim[\"ID.1\"], claim[\"Player.1\"])\n",
    "        claim_success = False if id_check != \"Successful\" else True\n",
    "        failure = \"Player Claim has an Invalid ID\" if id_check == False else failure\n",
    "\n",
    "        # Next, check that the ID of the player requested to drop is on the active roster\n",
    "        valid_dropping_id_check = False if claim[\"ID.2\"] not in current_rosters[top_priority].ID.values else True\n",
    "        claim_success = False if valid_dropping_id_check == False else claim_success\n",
    "        failure = \"Invalid ID for Dropping Player\" if valid_dropping_id_check == False else failure\n",
    "\n",
    "\n",
    "        # Maybe later include a check if the position of the pick up was valid\n",
    "\n",
    "        # Next, check that the pickup player is not on an active roster\n",
    "        player_availability_check = True if claim[\"ID.1\"] not in all_current_rostered_players.ID.values else False\n",
    "        claim_success = False if player_availability_check == False else claim_success\n",
    "        failure = \"Player Is Already Rostered On Another Team\" if player_availability_check == False else failure\n",
    "\n",
    "\n",
    "        # Finally, check that completing the transaction would result in a valid team\n",
    "        team_copy = current_rosters[top_priority].copy()\n",
    "        theoretical_drop = team_copy[team_copy.ID != claim[\"ID.2\"]]\n",
    "        theoretical_add = theoretical_drop.append(pd.DataFrame(claim.iloc[0:4].rename({x:x.split(\".\")[0] for x in claim.iloc[0:4].index})).T).reset_index(drop = True)\n",
    "        legal_team_check = check_valid_team(theoretical_add)\n",
    "        claim_success = False if legal_team_check == False else claim_success\n",
    "        failure = \"The Roster Would Not Be Legal If the Transaction Went Through\" if legal_team_check == False and valid_dropping_id_check != False else failure\n",
    "\n",
    "        # If the claim is still successfull, complete it, add the added player to the current roster list (so someone can't grab them this week too), update top priority, and move on\n",
    "        if claim_success == True:\n",
    "            # add the claim, and drop the player\n",
    "            current_rosters[top_priority] = current_rosters[top_priority].append(pd.DataFrame(claim.iloc[0:4].rename({x:x.split(\".\")[0] for x in claim.iloc[0:4].index})).T).reset_index(drop = True)\n",
    "            current_rosters[top_priority] = current_rosters[top_priority][current_rosters[top_priority].ID != claim[\"ID.2\"]].reset_index(drop = True)\n",
    "\n",
    "            # add the player to all currently rostered players\n",
    "            all_current_rostered_players = all_current_rostered_players.append(pd.DataFrame(claim.iloc[0:4].rename({x:x.split(\".\")[0] for x in claim.iloc[0:4].index})).T).reset_index(drop = True)\n",
    "\n",
    "            # remove the completed claim from top priorities claims list\n",
    "            all_requested_waiver_claims[top_priority] = all_requested_waiver_claims[top_priority].iloc[1:] if len(all_requested_waiver_claims[top_priority]) > 1 else pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            # remove the completed claim from top priorities claims list\n",
    "            all_requested_waiver_claims[top_priority] = all_requested_waiver_claims[top_priority].iloc[1:] if len(all_requested_waiver_claims[top_priority]) > 1 else pd.DataFrame()\n",
    "\n",
    "        # update top priority and remove a participant if they no longer have waiver claims\n",
    "        waiver_priority.append(waiver_priority.pop(waiver_priority.index(top_priority)))\n",
    "        num_claims = len(all_requested_waiver_claims[top_priority])\n",
    "        if num_claims == 0:\n",
    "            waiver_priority.remove(top_priority)\n",
    "            del all_requested_waiver_claims[top_priority]\n",
    "\n",
    "        # Fill in the waiver history sheet to be distributed\n",
    "        if claim_success == True:\n",
    "            waiver_history = waiver_history.append(pd.Series({\"Participant\":top_priority, \"Action\":\"Succesfully claimed {} and dropped {}\".format(claim[\"Player.1\"], claim[\"Player.2\"])}), ignore_index = True)\n",
    "        else:\n",
    "            waiver_history = waiver_history.append(pd.Series({\"Participant\":top_priority, \"Action\":\"Failed to claim {}. Reason: {}\".format(claim[\"Player.1\"], failure)}), ignore_index = True)\n",
    "\n",
    "\n",
    "        # Now Tackle IR Claims (Note: regular claims will take precedent over IR claims - thus the 2nd choice on IR claims.\n",
    "        participants_with_ir_claims = [x for x in injured_reserve_moves if injured_reserve_moves[x][\"Claim No.\"].iloc[2] == \"Yes\" or injured_reserve_moves[x][\"League.2\"].iloc[2]]\n",
    "        ir_priority = [x for x in total_waiver_priority if x in participants_with_ir_claims]\n",
    "\n",
    "        # Simply loop through the IR waiver wire, as participants can only make 1 claim at a time\n",
    "        for participant in ir_priority:\n",
    "            adding_a_player = \"Yes\" if injured_reserve_moves[participant][\"Claim No.\"].iloc[2] == \"Yes\" else \"No\"\n",
    "            if adding_a_player == \"Yes\":\n",
    "                claim = injured_reserve_moves[participant].copy()\n",
    "\n",
    "                # Get the info for both the player moving to IR and the player the participant is looking to claim\n",
    "                player_to_add = claim[\"Player.1\"].iloc[5]\n",
    "                id_to_add = claim[\"ID.1\"].iloc[5]\n",
    "\n",
    "                player_to_claim = claim[\"Player.1\"].iloc[8]\n",
    "                id_to_claim = claim[\"ID.1\"].iloc[8]\n",
    "\n",
    "                # Check that the player to add to IR is on the current roster\n",
    "                current_roster_check = False if claim[\"ID.1\"].iloc[5] not in current_rosters[participant].ID.values else True\n",
    "                ir_success = True if current_roster_check == True else False\n",
    "                ir_failure = \"The player to add to IR is not currently on the active roster\" if current_roster_check == False else \"The Injured Reserve Move was Succesfull\"\n",
    "\n",
    "                # Check that the player to add to the team has a valid id, and if not, move to the second choice\n",
    "                ir_id_check = claim_id_checker(claim[\"League.1\"].iloc[8], claim[\"ID.1\"].iloc[8], claim[\"Player.1\"].iloc[8])\n",
    "                ir_success = False if ir_id_check != \"Successful\" else True\n",
    "                ir_failure = \"Injured Reserve Player Claim has an Invalid ID\" if ir_id_check != \"Success\" else failure\n",
    "\n",
    "                secondary_selection = False\n",
    "                if ir_id_check != \"Successful\":\n",
    "                    secondary_selection = True\n",
    "                    ir_id_check = claim_id_checker(claim[\"League.1\"].iloc[9], claim[\"ID.1\"].iloc[9], claim[\"Player.1\"].iloc[9])\n",
    "                    ir_success = False if ir_id_check != \"Successful\" else True\n",
    "                    ir_failure = \"Both Injured Reserve Players Claims have Invalid IDs\" if ir_id_check != \"Success\" else failure\n",
    "\n",
    "                row = 9 if secondary_selection == True else 8\n",
    "\n",
    "\n",
    "                # Next, check that the pickup player is not on an active roster\n",
    "                ir_player_availability_check = True if claim[\"ID.1\"].iloc[row] not in all_current_rostered_players.ID.values else False\n",
    "                ir_success = False if ir_player_availability_check == False else ir_success\n",
    "                ir_failure = \"Injured Reserve Claim Player Is Already Rostered On Another Team\" if ir_player_availability_check == False else ir_failure\n",
    "\n",
    "                if ir_player_availability_check == False:\n",
    "                    secondary_selection = True\n",
    "                    ir_player_availabilit_check = True if claim[\"ID.1\"].iloc[9] not in all_current_rostered_players.ID.values else False\n",
    "                    ir_success = False if ir_player_availability_check == False else True\n",
    "                    ir_failure = \"The Injured Reserve Claim Player is Already Rostered On Another Team\" if ir_player_availability_check == False else failure\n",
    "\n",
    "                row = 9 if secondary_selection == True else 8\n",
    "\n",
    "\n",
    "                #BEFORE THE NEXT PART, WE SHOULD CHECK IF THE ADDING A NEW PLAYER IS LEFT BLANK, AND IF IT IT, IF THE RETURNING IR\n",
    "                # TO THE TEAM IS A YES. THEN IF SO, ADD THE OLD IR PERSON BACK ONTO THE TEAM\n",
    "                current_ir_return = \"No\"\n",
    "                if pd.isna(claim[\"ID.1\"].iloc[8]) == True and pd.isna(claim[\"ID.1\"].iloc[9]) == True:\n",
    "                    ir_failure = \"The Transaction Was Successfull\"\n",
    "                    ir_success = True\n",
    "\n",
    "                    current_ir_return = claim[\"League.2\"].iloc[4]\n",
    "                    if current_ir_return == \"Yes\":\n",
    "                        #check that completing the transaction would result in a valid team\n",
    "                        ir_team_copy = current_rosters[participant].copy()\n",
    "                        ir_theoretical_move = ir_team_copy.copy()\n",
    "\n",
    "                        old_ir_spot = ir_theoretical_move[ir_theoretical_move.Position == \"Injured Reserve\"]\n",
    "\n",
    "                        # Slide the old IR player back onto the roster\n",
    "                        ir_theoretical_move = ir_theoretical_move[ir_theoretical_move.Position != \"Injured Reserve\"]\n",
    "                        ir_theoretical_move = ir_theoretical_move.append(pd.DataFrame.from_dict({\"League\":[claim[\"Position.2\"].iloc[7]], \"Position\":[claim[\"Player.2\"].iloc[7]], \"Player\":[claim[\"ID.2\"].iloc[7]], \"ID\":[claim[\"Unnamed: 15\"].iloc[7]]})).reset_index(drop = True)\n",
    "\n",
    "                        # Slide the old healthy player into the IR\n",
    "                        ir_theoretical_move = ir_theoretical_move[ir_theoretical_move.ID != claim[\"ID.1\"].iloc[5]]\n",
    "                        ir_theoretical_move = ir_theoretical_move.append(pd.DataFrame.from_dict({\"League\":[np.NaN], \"Position\":[\"Injured Reserve\"], \"Player\":[claim[\"Player.1\"].iloc[5]], \"ID\":[claim[\"ID.1\"].iloc[5]]})).reset_index(drop = True)\n",
    "                        z = ir_theoretical_move\n",
    "                        ir_legal_team_check = check_valid_team(ir_theoretical_move)\n",
    "                        ir_success = False if ir_legal_team_check == False else ir_success\n",
    "                        ir_failure = \"The Roster Would Not Be Legal If the Transaction Went Through\" if ir_legal_team_check == False else failure\n",
    "\n",
    "                        # If the IR claim is still successfull, complete it, add the added player to the current roster list (so someone can't grab them this week too)\n",
    "                        if ir_success == True:\n",
    "                            # add the claim, and move the player\n",
    "                            current_rosters[participant] = ir_theoretical_move.copy()\n",
    "\n",
    "                    else:\n",
    "                        ir_failure = \"The Roster Would Not Be Legal If the Transaction Went Through\"\n",
    "\n",
    "                else:\n",
    "                    # Finally, check that completing the transaction would result in a valid team\n",
    "                    ir_team_copy = current_rosters[participant].copy()\n",
    "                    ir_theoretical_move = ir_team_copy.copy()\n",
    "\n",
    "                    old_ir_spot = ir_theoretical_move[ir_theoretical_move.Position == \"Injured Reserve\"]\n",
    "                    ir_theoretical_move = ir_theoretical_move[ir_theoretical_move.Position != \"Injured Reserve\"]\n",
    "\n",
    "                    ir_theoretical_move = ir_theoretical_move[ir_theoretical_move.ID != claim[\"ID.1\"].iloc[5]]\n",
    "                    ir_theoretical_move = ir_theoretical_move.append(pd.DataFrame.from_dict({\"League\":[np.NaN], \"Position\":[\"Injured Reserve\"], \"Player\":[claim[\"Player.1\"].iloc[5]], \"ID\":[claim[\"ID.1\"].iloc[5]]})).reset_index(drop = True)\n",
    "\n",
    "                    ir_theoretical_add = ir_theoretical_move.append(pd.DataFrame.from_dict({\"League\":[claim[\"League.1\"].iloc[row]], \"Position\":[claim[\"Position.1\"].iloc[row]], \"Player\":[claim[\"Player.1\"].iloc[row]], \"ID\":[claim[\"ID.1\"].iloc[row]]})).reset_index(drop = True)\n",
    "                    ir_legal_team_check = check_valid_team(ir_theoretical_add)\n",
    "                    ir_success = False if ir_legal_team_check == False else ir_success\n",
    "                    ir_failure = \"The Roster Would Not Be Legal If the Transaction Went Through\" if ir_legal_team_check == False else failure\n",
    "\n",
    "\n",
    "                    # If the IR claim is still successfull, complete it, add the added player to the current roster list (so someone can't grab them this week too)\n",
    "                    if ir_success == True:\n",
    "                        # add the claim, and drop the player\n",
    "                        current_rosters[participant] = current_rosters[participant][current_rosters[participant].Position != \"Injured Reserve\"].reset_index(drop = True)\n",
    "                        current_rosters[participant] = current_rosters[participant][current_rosters[participant].ID != claim[\"ID.1\"].iloc[5]].reset_index(drop = True)\n",
    "\n",
    "                        current_rosters[participant] = current_rosters[participant].append(pd.DataFrame.from_dict({\"League\":[np.NaN], \"Position\":[\"Injured Reserve\"], \"Player\":[claim[\"Player.1\"].iloc[5]], \"ID\":[claim[\"ID.1\"].iloc[5]]})).reset_index(drop = True)\n",
    "                        current_rosters[participant] = current_rosters[participant].append(pd.DataFrame.from_dict({\"League\":[claim[\"League.1\"].iloc[row]], \"Position\":[claim[\"Position.1\"].iloc[row]], \"Player\":[claim[\"Player.1\"].iloc[row]], \"ID\":[claim[\"ID.1\"].iloc[row]]})).reset_index(drop = True)\n",
    "\n",
    "\n",
    "                        # add the player to all currently rostered players\n",
    "                        all_current_rostered_players = all_current_rostered_players.append(pd.DataFrame.from_dict({\"League\":[claim[\"League.1\"].iloc[row]], \"Position\":[claim[\"Position.1\"].iloc[row]], \"Player\":[claim[\"Player.1\"].iloc[row]], \"ID\":[claim[\"ID.1\"].iloc[row]]})).reset_index(drop = True)\n",
    "\n",
    "\n",
    "                # Fill in the waiver history sheet to be distributed\n",
    "                if ir_success == True:\n",
    "                    ir_waiver_history = ir_waiver_history.append(pd.Series({\"Participant\":participant, \"Action\":\"Succesfully moved {} to Injured Reserve and added {} back to team\".format(claim[\"Player.1\"].iloc[5], claim[\"Player.1\"].iloc[row] if current_ir_return != \"Yes\" else claim[\"ID.2\"].iloc[7])}), ignore_index = True)\n",
    "                else:\n",
    "                    ir_waiver_history = ir_waiver_history.append(pd.Series({\"Participant\":participant, \"Action\":\"Failed to move {} to Injured Reserve. Reason: {}\".format(claim[\"Player.1\"].iloc[5], ir_failure)}), ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "            if injured_reserve_moves[participant][\"Claim No.\"].iloc[2] == \"No\" and injured_reserve_moves[participant][\"League.2\"].iloc[2] == \"Yes\":\n",
    "                old_ir = current_rosters[participant][current_rosters[participant].Position == \"Injured Reserve\"].copy()\n",
    "                claim = injured_reserve_moves[participant].copy()\n",
    "                simple_drop = True if claim[\"League.2\"].iloc[4] == \"No\" else \"False\"\n",
    "                if simple_drop == True:\n",
    "                    ir_success = True\n",
    "                    current_rosters[participant] = current_rosters[participant][current_rosters[participant].Position != \"Injured Reserve\"].reset_index(drop = True)\n",
    "                    current_rosters[participant] = current_rosters[participant].append(pd.DataFrame.from_dict({\"League\":[np.NaN], \"Position\":[\"Injured Reserve\"], \"Player\":[\"Empty\"], \"ID\":[np.NaN]})).reset_index(drop = True)    \n",
    "\n",
    "                else:\n",
    "                    ir_theoretical_team = current_rosters[participant].copy()\n",
    "\n",
    "                    # Drop the player listed to drop\n",
    "                    ir_theoretical_team = ir_theoretical_team[ir_theoretical_team.ID != claim[\"Unnamed: 15\"].iloc[10]]\n",
    "\n",
    "                    # Add the player on IR back to the team\n",
    "                    ir_theoretical_team = ir_theoretical_team.append(pd.DataFrame.from_dict({\"League\":[claim[\"Position.2\"].iloc[7]], \"Position\":[claim[\"Player.2\"].iloc[7]], \"Player\":[claim[\"ID.2\"].iloc[7]], \"ID\":[claim[\"Unnamed: 15\"].iloc[7]]})).reset_index(drop = True)\n",
    "\n",
    "                    ir_legal_team_check_ii = check_valid_team(ir_theoretical_team)\n",
    "                    ir_success_ii = False if ir_legal_team_check_ii == False else True\n",
    "                    ir_failure_ii = \"The Roster Would Not Be Legal If the Transaction Went Through\" if ir_legal_team_check_ii == False else \"Success\"\n",
    "\n",
    "                    if ir_success_ii == True:\n",
    "                        # Remove the old IR player, and add him back in his actual position\n",
    "                        current_rosters[participant] = current_rosters[participant][current_rosters[participant].Position != \"Injured Reserve\"].reset_index(drop = True)\n",
    "                        current_rosters[participant] = current_rosters[participant].append(pd.DataFrame.from_dict({\"League\":[claim[\"Position.2\"].iloc[7]], \"Position\":[claim[\"Player.2\"].iloc[7]], \"Player\":[claim[\"ID.2\"].iloc[7]], \"ID\":[claim[\"Unnamed: 15\"].iloc[7]]})).reset_index(drop = True)\n",
    "\n",
    "                        # Remove the player manually listed for a drop given the addition of the IR Player\n",
    "                        current_rosters[participant] = current_rosters[participant][current_rosters[participant].ID != claim[\"Unnamed: 15\"].iloc[10]]\n",
    "\n",
    "                        # Add back an empty IR spot\n",
    "                        current_rosters[participant] = current_rosters[participant].append(pd.DataFrame.from_dict({\"League\":[np.NaN], \"Position\":[\"Injured Reserve\"], \"Player\":[\"Empty\"], \"ID\":[np.NaN]})).reset_index(drop = True)\n",
    "\n",
    "                # Fill in the waiver history sheet to be distributed\n",
    "                if ir_success_ii == True:\n",
    "                    if simple_drop == True:\n",
    "                        ir_waiver_history = ir_waiver_history.append(pd.Series({\"Participant\":participant, \"Action\":\"Succesfully Removed {} From The Injured Reserve\".format(old_ir.Player.iloc[0])}), ignore_index = True)\n",
    "                    else:\n",
    "                        ir_waiver_history = ir_waiver_history.append(pd.Series({\"Participant\":participant, \"Action\":\"Succesfully Added {} Back From The Injured Reserve and Dropped {}\".format(old_ir.Player.iloc[0], claim[\"ID.2\"].iloc[10])}), ignore_index = True)\n",
    "\n",
    "                else:\n",
    "                    ir_waiver_history = ir_waiver_history.append(pd.Series({\"Participant\":participant, \"Action\":\"Failed to remove {} to Injured Reserve. Reason: {}\".format(claim[\"ID.2\"].iloc[6], ir_failure_ii)}), ignore_index = True)\n",
    "\n",
    "    waiver_history = waiver_history.append(ir_waiver_history)\n",
    "    \n",
    "    return current_rosters, waiver_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions to run the League"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_fantasy_points(raw_stats_line, league, points_dict, postitional_dict):\n",
    "    raw_stats_line = raw_stats_line.fillna(0)\n",
    "    position = raw_stats_line.Position\n",
    "    positional_scoring_categories = positional_scoring_dict[league][position]\n",
    "    total_points = 0\n",
    "    for col in raw_stats_line.index:\n",
    "        if col in positional_scoring_categories:\n",
    "            total_points += raw_stats_line[col] * points_dict[league][col]\n",
    "    return round(total_points, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current full rosters and starting 9s from the Current Rosters Excel\n",
    "def get_current_rosters(rosters_file_path):\n",
    "    rosters = {}\n",
    "    for participant in waiver_participants:\n",
    "        rosters[participant] = {}\n",
    "\n",
    "        data = pd.read_excel(rosters_file_path, sheet_name = participant)\n",
    "\n",
    "        # Grab the full current roster and store it in the rosters dictionary\n",
    "        full_roster = data.iloc[4:, 1:5]\n",
    "        full_roster.columns = [\"League\", \"Position\", \"Player\", \"ID\"]\n",
    "        rosters[participant][\"Full Roster\"] = full_roster.dropna(how = \"all\").reset_index(drop = True)\n",
    "\n",
    "        # Grab the starters and store it in the rosters dictionary\n",
    "        starters = data.iloc[5:, 7:]\n",
    "        starters.columns = [\"League\", \"Position\", \"Player\", \"ID\"]\n",
    "        rosters[participant][\"Starters\"] = starters.dropna(how = \"all\").reset_index(drop = True)\n",
    "\n",
    "    return rosters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_league_stats(day, month, year):\n",
    "    raw_nfl_stats = get_daily_nfl_stats(day, month, year)\n",
    "    nfl_stats = transform_nfl_stats(raw_nfl_stats)\n",
    "    time.sleep(20)\n",
    "    \n",
    "    raw_nhl_stats = get_daily_nhl_stats(day, month, year)\n",
    "    nhl_stats = transform_nhl_stats(raw_nhl_stats)\n",
    "    time.sleep(20)\n",
    "    \n",
    "    raw_nba_stats = get_daily_nba_stats(day, month, year)\n",
    "    nba_stats = transform_nba_stats(raw_nba_stats)\n",
    "    time.sleep(20)\n",
    "    \n",
    "    # If there are no games on the given day, unlike the other sports the MLB run will not fail quietly --> set up a try except with a visual warning\n",
    "    try:\n",
    "        raw_mlb_stats = get_daily_mlb_stats(day, month, year)\n",
    "        mlb_stats = transform_mlb_stats(raw_mlb_stats)\n",
    "        return {\"NFL\":nfl_stats, \"NHL\":nhl_stats, \"NBA\":nba_stats, \"MLB\":mlb_stats}\n",
    "  \n",
    "    except:\n",
    "        print(\"An error was thrown pulling MLB stats. If the MLB is in season, investigate the error further.\")\n",
    "        time.sleep(6)\n",
    "        mlb_stats = pd.DataFrame()\n",
    "        clear_output(wait = False)\n",
    "\n",
    "        \n",
    "    return {\"NFL\":nfl_stats, \"NHL\":nhl_stats, \"NBA\":nba_stats, \"MLB\":mlb_stats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build period stats for scoring\n",
    "def assign_daily_stats(period, str_date, daily_data, rosters_file_path):\n",
    "    str_date = str_date.split(\"/\")[0].zfill(2) + \"/\" + str_date.split(\"/\")[1].zfill(2) + \"/\" + str_date.split(\"/\")[2].zfill(2)\n",
    "    participant_rosters = get_current_rosters(rosters_file_path)\n",
    "    \n",
    "    # Pull the stats from the period so far is it's not the first day of the period, else start a new dict\n",
    "    if str_date not in start_dates:\n",
    "        current_period_stats = pkl.load(open(\"/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Matchups Data/Period {}.pkl\".format(period), \"rb\"))\n",
    "    else:\n",
    "        current_period_stats = {}\n",
    "        for participant in waiver_participants:\n",
    "            current_period_stats[participant] = {}\n",
    "            for league in [\"MLB\", \"NFL\", \"NHL\", \"NBA\"]:\n",
    "                current_period_stats[participant][league] = pd.DataFrame()\n",
    "                \n",
    "    # Check that we are in a 2 day transaction period, and if so, just return the current period stats unadjusted, in case this is run during that period\n",
    "    # if str_date not in playing_dates:\n",
    "    #     return current_period_stats\n",
    "\n",
    "    for participant in waiver_participants:\n",
    "        participant_starters = participant_rosters[participant][\"Starters\"]\n",
    "\n",
    "        for league in [\"MLB\", \"NFL\", \"NHL\", \"NBA\"]:      \n",
    "            if len(daily_data[league]) > 0:\n",
    "                \n",
    "                daily_league_data = daily_data[league]\n",
    "                league_team_ids = participant_starters[participant_starters.League == league].ID\n",
    "                team_daily_league_stats = daily_data[league][\"players\"][daily_league_data[\"players\"][\"Player ID\"].isin([x for x in league_team_ids]) == True]\n",
    "                if league == \"NFL\":\n",
    "                    team_daily_league_stats = team_daily_league_stats.append(daily_data[league][\"teams\"][daily_league_data[\"teams\"][\"Player ID\"].isin([str(x) for x in league_team_ids]) == True])\n",
    "                # Add the data for the participants players for the day into the stats for the whole period so far\n",
    "                if len(current_period_stats[participant][league]) != 0:\n",
    "                    current_period_stats[participant][league] = current_period_stats[participant][league].append(team_daily_league_stats)\n",
    "                else:\n",
    "                    current_period_stats[participant][league] = team_daily_league_stats\n",
    "                    \n",
    "                # Attatch the position the players are starting in in the current period stats for later reference when scoring\n",
    "                current_period_stats[participant][league][\"Position\"] = current_period_stats[participant][league][\"Player ID\"].apply(lambda x: participant_starters[participant_starters.ID == x].Position.iloc[0])\n",
    "    \n",
    "    \n",
    "    pkl.dump(current_period_stats, open(\"/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Matchups Data/Period {}.pkl\".format(period), \"wb\"))\n",
    "                    \n",
    "    return current_period_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the cumulative stats for all participants for a period, determine the matchups and score everything\n",
    "def score_matchups(period, period_data, matchup_data_path):\n",
    "    participants = pd.read_excel(matchup_data_path, sheet_name = \"League View\").iloc[[2,18]][[\"Unnamed: 2\", \"Unnamed: 7\",\"Unnamed: 12\", \"Unnamed: 17\"]]\n",
    "    matchup_dict = {1:{participants[\"Unnamed: 2\"].iloc[0]:{}, participants[\"Unnamed: 7\"].iloc[0]:{}},\n",
    "                    2:{participants[\"Unnamed: 12\"].iloc[0]:{}, participants[\"Unnamed: 17\"].iloc[0]:{}},\n",
    "                    3:{participants[\"Unnamed: 2\"].iloc[1]:{}, participants[\"Unnamed: 7\"].iloc[1]:{}},\n",
    "                    4:{participants[\"Unnamed: 12\"].iloc[1]:{}, participants[\"Unnamed: 17\"].iloc[1]:{}}}\n",
    "    \n",
    "\n",
    "    # Assign the stats for the participants team for the period to the participant\n",
    "    for matchup in matchup_dict:\n",
    "        for participant in matchup_dict[matchup]:\n",
    "            for league in [\"NFL\", \"MLB\", \"NHL\", \"NBA\"]:\n",
    "                matchup_dict[matchup][participant][league] = pd.DataFrame()\n",
    "                if league in period_data[participant].keys():\n",
    "                    df = period_data[participant][league]\n",
    "                    if len(df) > 0:\n",
    "                        matchup_dict[matchup][participant][league] = matchup_dict[matchup][participant][league].append(df)\n",
    "      \n",
    "    # Score the stats for the participant for the period\n",
    "    for matchup in matchup_dict:\n",
    "        for participant in matchup_dict[matchup]:\n",
    "            for league in [\"NFL\", \"MLB\", \"NHL\", \"NBA\"]:\n",
    "                if len(matchup_dict[matchup][participant][league]) > 0:\n",
    "                    matchup_dict[matchup][participant][league][\"Fantasy Points\"] = matchup_dict[matchup][participant][league].apply(lambda x: assign_fantasy_points(x, league, scoring_dict, positional_scoring_dict), axis = 1)\n",
    "\n",
    "    # Consolidate the matchup_dict\n",
    "    scored_matchup_dict = {}\n",
    "    for matchup in matchup_dict:\n",
    "        scored_matchup_dict[matchup] = {}\n",
    "        for participant in matchup_dict[matchup]:\n",
    "            scored_matchup_dict[matchup][participant] = {}\n",
    "            participant_period_stats = pd.DataFrame()\n",
    "            for league in matchup_dict[matchup][participant]:\n",
    "                df = matchup_dict[matchup][participant][league]\n",
    "                if len(df) > 0:\n",
    "                    participant_period_stats = participant_period_stats.append(df)\n",
    "                    total_participant_period_points = participant_period_stats[\"Fantasy Points\"].sum()\n",
    "            \n",
    "                scored_matchup_dict[matchup][participant] = {}\n",
    "                starter_cols = [\"Name\", \"Player ID\", \"Date\", \"Position\", \"Fantasy Points\"]\n",
    "                scored_matchup_dict[matchup][participant][\"stats\"] = participant_period_stats[starter_cols + [col for col in participant_period_stats.columns if col not in starter_cols]] if len(participant_period_stats) > 0 else pd.DataFrame()\n",
    "                scored_matchup_dict[matchup][participant][\"points\"] = total_participant_period_points if len(participant_period_stats) > 0 else 0\n",
    "    \n",
    "    pkl.dump(scored_matchup_dict, open(\"All Sports Fantasy/Scored Matchups/Period {}\".format(period), \"wb\"))\n",
    "    \n",
    "    return scored_matchup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_league(period, scored_matchup_dict, year, month, day):\n",
    "    # Write the League\n",
    "    writer = pd.ExcelWriter('/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Matchup Printouts/Period {} - {}:{}:{}.xlsx'.format(period, year, str(month).zfill(2), str(day).zfill(2)), engine='xlsxwriter')\n",
    "    participants = []\n",
    "    v_indent_counter_I = 2\n",
    "    v_indent_counter_II = 3\n",
    "    \n",
    "    \n",
    "    for matchup in scored_matchup_dict:\n",
    "        lens = []\n",
    "        p1 = list(scored_matchup_dict[matchup].keys())[0]\n",
    "        p2 = list(scored_matchup_dict[matchup].keys())[1]\n",
    "        h_indent_counter = 3\n",
    "        v_indent_counter = 2\n",
    "        h_indent_counter_I = 1\n",
    "        \n",
    "\n",
    "        for participant in scored_matchup_dict[matchup]:\n",
    "            df = scored_matchup_dict[matchup][participant][\"stats\"]\n",
    "            p_cum = scored_matchup_dict[matchup][participant][\"stats\"].groupby(by = \"Name\", dropna = False).sum()\n",
    "            lens.append(len(p_cum))\n",
    "            df.to_excel(writer, sheet_name=\"{} vs. {}\".format(p1, p2), startcol=h_indent_counter, startrow=v_indent_counter, index = False) # Default position, cell A1.\n",
    "            p_cum.to_excel(writer, sheet_name=\"Cumulative Period Stats\", startcol=h_indent_counter_I, startrow=v_indent_counter_I, index = True)\n",
    "            \n",
    "            \n",
    "            v_indent_counter += len(df) + 3\n",
    "            h_indent_counter_I += len(p_cum.columns) + 2\n",
    "            \n",
    "        v_indent_counter_I += max(lens) + 4    \n",
    "        h_indent_counter_I += 2\n",
    "        \n",
    "\n",
    "    writer.save() \n",
    "    \n",
    "    # Format the League\n",
    "    \n",
    "    workbook = openpyxl.load_workbook('/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Matchup Printouts/Period {} - {}:{}:{}.xlsx'.format(period, year, str(month).zfill(2), str(day).zfill(2)))\n",
    "    \n",
    "    standard_side = Side(border_style=\"thin\", color = \"000000\")\n",
    "    border = Border(top=standard_side, bottom=standard_side, right=standard_side, left=standard_side)\n",
    "    alignment = Alignment(horizontal='center', wrap_text=False)\n",
    "    gray_fill = PatternFill(start_color='B2B0B4', end_color='B2B0B4', fill_type='solid')\n",
    "    orange_fill = PatternFill(start_color='F3A321', end_color='F3A321', fill_type='solid')\n",
    "    bold = Font(bold=True)\n",
    "    \n",
    "    for matchup in scored_matchup_dict:\n",
    "        p1 = list(scored_matchup_dict[matchup].keys())[0]\n",
    "        p2 = list(scored_matchup_dict[matchup].keys())[1]\n",
    "        worksheet = workbook[\"{} vs. {}\".format(p1, p2)]\n",
    "        \n",
    "        df1 = scored_matchup_dict[matchup][p1][\"stats\"]\n",
    "        df1_rows = len(df1)\n",
    "        df1_columns = len(df1.columns)\n",
    "        \n",
    "        df2 = scored_matchup_dict[matchup][p2][\"stats\"]\n",
    "        df2_rows = len(df2)\n",
    "        df2_columns = len(df2.columns)\n",
    "        \n",
    "        df1_points = scored_matchup_dict[matchup][p1][\"points\"] if scored_matchup_dict[matchup][p1][\"points\"] != pd.DataFrame else 0\n",
    "        df2_points = scored_matchup_dict[matchup][p2][\"points\"] if scored_matchup_dict[matchup][p2][\"points\"] != pd.DataFrame else 0\n",
    "       \n",
    "        \n",
    "        # Alter the top df\n",
    "        for col in [xlsx_columns[x+4] for x in range(df1_columns)]:\n",
    "            for row in range(4, df1_rows+4):\n",
    "                worksheet[\"{}{}\".format(col,row)].border = border\n",
    "                worksheet[\"{}{}\".format(col,row)].alignment = alignment\n",
    "            for row in range(3,4):\n",
    "                worksheet[\"{}{}\".format(col,row)].fill = gray_fill\n",
    "        \n",
    "            #worksheet.column_dimensions[col].bestFit = True\n",
    "                    \n",
    "        # Alter the bottom df         \n",
    "        for col in [xlsx_columns[x+4] for x in range(df2_columns)]:\n",
    "            for row in range(df1_rows + 7, df1_rows+7+df2_rows):\n",
    "                worksheet[\"{}{}\".format(col,row)].border = border\n",
    "                worksheet[\"{}{}\".format(col,row)].alignment = alignment\n",
    "            for row in range(df1_rows + 6,df1_rows + 7):\n",
    "                worksheet[\"{}{}\".format(col,row)].fill = gray_fill\n",
    "                \n",
    "            worksheet.column_dimensions[col].bestFit = True\n",
    "            \n",
    "        # Put in scores in the matchups\n",
    "        for col in [xlsx_columns[8]]:\n",
    "            for row in [2, df1_rows + 5]:\n",
    "                if row == 2:\n",
    "                    worksheet[\"{}{}\".format(col,row)].value = scored_matchup_dict[matchup][p1][\"points\"]\n",
    "                    \n",
    "                elif row == df1_rows + 5:\n",
    "                    worksheet[\"{}{}\".format(col,row)].value = scored_matchup_dict[matchup][p2][\"points\"]\n",
    "                    \n",
    "                worksheet[\"{}{}\".format(col,row)].fill = orange_fill\n",
    "                worksheet[\"{}{}\".format(col,row)].alignment = alignment\n",
    "                worksheet[\"{}{}\".format(col,row)].border = border\n",
    "                worksheet[\"{}{}\".format(col,row)].font = bold\n",
    "                \n",
    "                \n",
    "        # Format the Cumulative Stats\n",
    "        worksheet = workbook[\"Cumulative Period Stats\"]\n",
    "        for col in [xlsx_columns[x+2] for x in range(df1_columns-3)]:\n",
    "            for row in range(v_indent_counter_II, v_indent_counter_II + 1):\n",
    "                worksheet[\"{}{}\".format(col,row)].alignment = alignment\n",
    "                worksheet[\"{}{}\".format(col,row)].fill = gray_fill\n",
    "                \n",
    "        for col in [xlsx_columns[x+df1_columns] for x in range(df2_columns - 3)]:\n",
    "            for row in range(v_indent_counter_II, v_indent_counter_II + 1):\n",
    "                worksheet[\"{}{}\".format(col,row)].alignment = alignment\n",
    "                worksheet[\"{}{}\".format(col,row)].fill = gray_fill\n",
    "                \n",
    "        v_indent_counter_II += max(lens) + 4\n",
    "    \n",
    "    \n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "    \n",
    "    workbook.save('/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Matchup Printouts/Period {} - {}:{}:{}.xlsx'.format(period, year, str(month).zfill(2), str(day).zfill(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Update The League (Run Above Functions) and Write to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_league(year, month, day, start_dates):\n",
    "    current_period = get_current_period(start_dates, year, month, day)\n",
    "    \n",
    "    roster_file_path = \"/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Roster Sheets/Period {} Rosters.xlsx\".format(current_period)\n",
    "    \n",
    "    daily_data = get_daily_league_stats(day, month, year)\n",
    "    \n",
    "    current_period_stats_by_team = assign_daily_stats(current_period, \"{}/{}/{}\".format(year, month, day), daily_data, roster_file_path)\n",
    "    \n",
    "    scored_matchup_dict = score_matchups(current_period, current_period_stats_by_team, roster_file_path)\n",
    "    \n",
    "    output_league(current_period, scored_matchup_dict, year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster_file_path = \"/Users/jaredzirkes/Desktop/Python/All Sports Fantasy/Roster Sheets/Period 22 Rosters.xlsx\"\n",
    "y = assign_daily_stats(22, \"2022/11/4\", x, roster_file_path)\n",
    "z = score_matchups(22, y, roster_file_path)\n",
    "output_league(22, z, 2022, 11, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in range(25, 26):\n",
    "#     print(n)\n",
    "#     clear_output(wait=True)\n",
    "#     run_league(2022, 10, n, start_dates)\n",
    "#     time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
